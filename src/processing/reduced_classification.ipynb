{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import tsfel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, f1_score, log_loss, confusion_matrix, classification_report)\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_robustness(metric_name, metric_values, threshold_percent=10):\n",
    "    \"\"\"\n",
    "    Check the robustness of a model based on k-fold metric values.\n",
    "    \n",
    "    A model is considered robust if the coefficient of variation (CV),\n",
    "    defined as (standard deviation / mean) * 100, is less than threshold_percent.\n",
    "    \n",
    "    Parameters:\n",
    "        metric_values (list or np.array): List/array of metric values from each fold.\n",
    "        threshold_percent (float): The maximum allowed CV percentage (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the model is robust (CV < threshold_percent), False otherwise.\n",
    "    \"\"\"\n",
    "    metric_values = np.array(metric_values)\n",
    "    mean_val = np.mean(metric_values)\n",
    "    std_val = np.std(metric_values)\n",
    "    \n",
    "    # Avoid division by zero:\n",
    "    if mean_val == 0:\n",
    "        cv = float('inf')\n",
    "    else:\n",
    "        cv = (std_val / mean_val) * 100\n",
    "\n",
    "    print(f\"[{metric_name}] Metric Mean: {mean_val:.4f}\")\n",
    "    print(f\"[{metric_name}] Metric Standard Deviation: {std_val:.4f}\")\n",
    "    print(f\"[{metric_name}] Coefficient of Variation (CV): {cv:.2f}%\")\n",
    "    \n",
    "    if cv < threshold_percent:\n",
    "        print(f\"[{metric_name}] Model is robust (CV < {threshold_percent}%)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"[{metric_name}] Model is not robust (CV >= {threshold_percent}%)\")\n",
    "        return False\n",
    "    \n",
    "def get_movement_data(subject_id, base_path, sampling_rate):\n",
    "    # File path handling\n",
    "    path = Path(base_path) / f'{subject_id}_ml.bin'\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Movement data not found for subject {subject_id}\")\n",
    "    \n",
    "    # Load raw data\n",
    "    raw_data = np.fromfile(path, dtype=np.float32)\n",
    "    \n",
    "    # Channel configuration\n",
    "    tasks = [\"Relaxed1\", \"Relaxed2\", \"RelaxedTask1\", \"RelaxedTask2\", \n",
    "             \"StretchHold\", \"HoldWeight\", \"DrinkGlas\", \"CrossArms\", \n",
    "             \"TouchNose\", \"Entrainment1\", \"Entrainment2\"]\n",
    "    wrists = [\"Left\", \"Right\"]\n",
    "    sensors = [\"Accelerometer\", \"Gyroscope\"]\n",
    "    axes = [\"X\", \"Y\", \"Z\"]\n",
    "    \n",
    "    # Calculate expected parameters\n",
    "    n_channels = len(tasks) * len(wrists) * len(sensors) * len(axes)\n",
    "\n",
    "    # Even though the duration was 10.24 per assessment, the first ~0.5 seconds are not used and thus\n",
    "    # the preprocessed data has only 9.76 seconds of data\n",
    "    expected_duration = 9.76  # seconds per assessment\n",
    "    expected_timepoints = int(expected_duration * sampling_rate)  # 976\n",
    "    \n",
    "    # Validate data size\n",
    "    expected_size = n_channels * expected_timepoints\n",
    "    #print(f\"Expected size: {expected_size} elements\")\n",
    "    if len(raw_data) != expected_size:\n",
    "        raise ValueError(f\"Unexpected data size for {subject_id}: \"\n",
    "                         f\"Got {len(raw_data)} elements, expected {expected_size}\")\n",
    "    \n",
    "    return {\n",
    "        'tasks': tasks,\n",
    "        'wrists': wrists,\n",
    "        'sensors': sensors,\n",
    "        'axes': axes,\n",
    "        'raw_data': raw_data,\n",
    "        'timepoints': expected_timepoints,\n",
    "    }\n",
    "    \n",
    "def load_movement_features(subject_id, base_path='../../reduced-data/preprocessed/movement/', sampling_rate=100):\n",
    "    \"\"\"\n",
    "    Load and structure movement data from binary files with proper validation\n",
    "    \n",
    "    Args:\n",
    "        subject_id (str): Subject identifier (e.g., '001')\n",
    "        base_path (str): Base directory for movement data\n",
    "        sampling_rate (int): Sampling rate in Hz (used for validation)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Structured data with keys as channel names and values as time series arrays\n",
    "    \"\"\"\n",
    "    movement_data = get_movement_data(subject_id, base_path, sampling_rate)\n",
    "    tasks = movement_data['tasks']\n",
    "    wrists = movement_data['wrists']\n",
    "    sensors = movement_data['sensors']\n",
    "    axes = movement_data['axes']\n",
    "    raw_data = movement_data['raw_data']\n",
    "    timepoints = movement_data['timepoints']\n",
    "    \n",
    "    # Reshape and structure the data\n",
    "    structured_data = {}\n",
    "    channel_idx = 0\n",
    "    \n",
    "    for task in tasks:\n",
    "        for wrist in wrists:\n",
    "            for sensor in sensors:\n",
    "                for axis in axes:\n",
    "                    # Extract channel data\n",
    "                    start = channel_idx * timepoints\n",
    "                    end = (channel_idx + 1) * timepoints\n",
    "                    \n",
    "                    # Create channel name\n",
    "                    channel_name = f\"{task}_{wrist}_{sensor.split(' ')[0]}_{axis}\"\n",
    "                    \n",
    "                    structured_data[channel_name] = raw_data[start:end]\n",
    "                    \n",
    "                    channel_idx += 1\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "def load_movement_features_continuous(subject_id, base_path='../../reduced-data/preprocessed/movement/', sampling_rate=100):\n",
    "    \"\"\"\n",
    "    Load and structure movement data by concatenating across tasks for each (wrist, sensor, axis).\n",
    "    \n",
    "    Instead of one series per task, produces one long series per channel (wrist/sensor/axis)\n",
    "    by appending each task’s trimmed data end-to-end.\n",
    "    \n",
    "    Args:\n",
    "        subject_id (str): Subject identifier (e.g., '001')\n",
    "        base_path (str): Base directory for movement data\n",
    "        sampling_rate (int): Sampling rate in Hz (used for validation)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are \"{wrist}_{sensor}_{axis}\", values are 1D numpy arrays of length\n",
    "              (expected_timepoints - skip) * n_tasks\n",
    "    \"\"\"\n",
    "    movement_data = get_movement_data(subject_id, base_path, sampling_rate)\n",
    "    tasks = movement_data['tasks']\n",
    "    wrists = movement_data['wrists']\n",
    "    sensors = movement_data['sensors']\n",
    "    axes = movement_data['axes']\n",
    "    raw_data = movement_data['raw_data']\n",
    "    timepoints = movement_data['timepoints']\n",
    "    \n",
    "    # Prepare container: one list per (wrist, sensor, axis)\n",
    "    cont = {\n",
    "        f\"{wrist}_{sensor}_{axis}\": []\n",
    "        for wrist in wrists\n",
    "        for sensor in sensors\n",
    "        for axis in axes\n",
    "    }\n",
    "    \n",
    "    # Slice raw per (task, wrist, sensor, axis), trim, and append\n",
    "    idx = 0\n",
    "    for task in tasks:\n",
    "        for wrist in wrists:\n",
    "            for sensor in sensors:\n",
    "                for axis in axes:\n",
    "                    start = idx * timepoints\n",
    "                    end = start + timepoints\n",
    "                    segment = raw_data[start:end]\n",
    "                    key = f\"{wrist}_{sensor}_{axis}\"\n",
    "                    cont[key].append(segment)\n",
    "                    idx += 1\n",
    "    \n",
    "    # Concatenate per key\n",
    "    for key, chunks in cont.items():\n",
    "        cont[key] = np.concatenate(chunks)\n",
    "    \n",
    "    return cont\n",
    "\n",
    "def extract_tsfel_ts_features(channel_data, domain=None, fs=100):\n",
    "    \"\"\"\n",
    "    Extract TSFEL features from a single-channel time series.\n",
    "    \n",
    "    Args:\n",
    "        channel_data (np.ndarray): 1D array of time series values.\n",
    "        domain: (str): Domain of features to extract (default: 'all').\n",
    "            - 'statistical', 'temporal', 'spectral', 'fractal': Includes the corresponding feature domain.\n",
    "            - 'all': Includes all available feature domains.\n",
    "            - list of str: A combination of the above strings, e.g., ['statistical', 'temporal'].\n",
    "            - None: By default, includes the 'statistical', 'temporal', and 'spectral' domains.\n",
    "        fs (int): Sampling frequency (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of TSFEL features.\n",
    "    \"\"\"\n",
    "    # Obtain a default configuration covering all domains.\n",
    "    cfg = tsfel.get_features_by_domain(domain)\n",
    "\n",
    "    # Extract features; the result is a DataFrame with one row.\n",
    "    features_df = tsfel.time_series_features_extractor(cfg, channel_data, fs=fs, verbose=0)\n",
    "    \n",
    "    # Flatten to 1D numpy array and return.\n",
    "    return features_df.values.flatten()\n",
    "\n",
    "def extract_ts_features(label, channel_data, domain=None, fs=None):\n",
    "    if label == 'basic':\n",
    "        features = [\n",
    "            np.mean(channel_data), # Mean of the signal\n",
    "            np.std(channel_data), # Standard deviation\n",
    "            np.min(channel_data), # Minimum value\n",
    "            np.max(channel_data), # Maximum value\n",
    "            np.percentile(channel_data, 25), # 25th percentile\n",
    "            np.percentile(channel_data, 75), # 75th percentile\n",
    "            np.var(channel_data), # Variance\n",
    "            len(np.where(np.diff(np.sign(channel_data)))[0]) / len(channel_data),  # Zero-crossing rate\n",
    "            np.sqrt(np.mean(channel_data**2))  # Root Mean Square (RMS)\n",
    "        ]\n",
    "\n",
    "        # Return features as a numpy array\n",
    "        features = np.array(features)\n",
    "        return features\n",
    "    else:\n",
    "        return extract_tsfel_ts_features(channel_data, domain=domain, fs=fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Requisite: Python 3.12 (por catboost). brew install libomp para xgboost\n",
    "\n",
    "tsfel explicaciones: https://github.com/fraunhoferportugal/tsfel/blob/v0.1.9/tsfel/feature_extraction/features.json\n",
    "\n",
    "En base a los datos preprocesados, entrenaremos modelos de clasificacion bajo distintos escenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:17<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic shape: (20, 1218)\n",
      "TSFEL-temporal shape: (20, 1878)\n",
      "TSFEL-statistical shape: (20, 402)\n",
      "TSFEL-spectral shape: (20, 1362)\n",
      "questionnaire-only shape: (20, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar metadatos\n",
    "file_list = pd.read_csv('../../reduced-data/preprocessed/file_list.csv',  dtype={'id': str})\n",
    "\n",
    "movement_data_per_subject = {}\n",
    "sampling_rate = 100\n",
    "\n",
    "# In the normal case, we have 132 channels and every channel has 976 time points (giving 128832 which is correct)\n",
    "\n",
    "# Create multiple cases so we can check each model independently:\n",
    "# 1. Basic statistical features (Reduce 128832 features [976 features p/c] to 1188 features [9 features p/c]) + questionnaire data\n",
    "# 2. TSFEL only temporal features (Reduce 128832 features [976 features p/c] to 1848 features [14 features p/c]  + questionnaire data\n",
    "# 3. [NOT DOING - TOO BIG] TSFEL only statistical features (Reduce 128832 features [976 features p/c] to 4092 features [31 features p/c]  + questionnaire data\n",
    "# 4. [NOT DOING - TOO BIG] TSFEL only spectral features (Reduce 128832 features [976 features p/c] to 14652 features [111 features p/c]  + questionnaire data\n",
    "# 5. Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "# In the continuous case, we have 12 channels but every channel has 10736 time points (giving 128832 which is correct)\n",
    "\n",
    "# 1. [NOT DOING - DONE ON NORMAL] Basic statistical features (Reduce 128832 features [10736 features p/c] to 108 features [9 features p/c]) + questionnaire data\n",
    "# 2. [NOT DOING - DONE ON NORMAL] TSFEL only temporal features (Reduce 128832 features [10736 features p/c] to 168 features [14 features p/c]  + questionnaire data\n",
    "# 3. TSFEL only statistical features (Reduce 128832 features [10736 features p/c] to 372 features [31 features p/c]  + questionnaire data\n",
    "# 4. TSFEL only spectral features (Reduce 128832 features [10736 features p/c] to 1332 features [111 features p/c]  + questionnaire data\n",
    "# 5. Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "# For efficiency purposes, we do\n",
    "# 1. (Normal) Basic statistical features (Reduce 128832 features [976 features p/c] to 1188 features [9 features p/c]) + questionnaire data\n",
    "# 2. (Normal) TSFEL only temporal features (Reduce 128832 features [976 features p/c] to 1848 features [14 features p/c]  + questionnaire data\n",
    "# 3. (Cont)   TSFEL only statistical features (Reduce 128832 features [10736 features p/c] to 372 features [31 features p/c]  + questionnaire data\n",
    "# 4. (Cont)   TSFEL only spectral features (Reduce 128832 features [10736 features p/c] to 1332 features [111 features p/c]  + questionnaire data\n",
    "# 5. (N/A)    Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "pipeline_labels = ['basic', 'TSFEL-temporal', 'TSFEL-statistical', 'TSFEL-spectral', 'questionnaire-only']\n",
    "\n",
    "pipeline_args = [\n",
    "    {'domain': None, 'fs': None, 'ts_mode': None},  # Basic statistical features\n",
    "    {'domain': 'temporal', 'fs': sampling_rate, 'ts_mode': None},  # TSFEL-temporal\n",
    "    {'domain': 'statistical', 'fs': sampling_rate, 'ts_mode': 'continuous'},  # TSFEL-statistical\n",
    "    {'domain': 'spectral', 'fs': sampling_rate, 'ts_mode': 'continuous'},  # TSFEL-spectral\n",
    "    None,  # Questionnaire-only\n",
    "]\n",
    "\n",
    "# X must be 2D (samples, features)\n",
    "X_vals = {label: [] for label in pipeline_labels}\n",
    "y_vals = {label: [] for label in pipeline_labels}\n",
    "\n",
    "# First, load timeseries data and extract features\n",
    "for _, row in tqdm(file_list.iterrows(), total=len(file_list)):\n",
    "    # Cargar cuestionario\n",
    "    quest_data = np.fromfile(f'../../reduced-data/preprocessed/questionnaire/{row[\"id\"]}_ml.bin', \n",
    "                           dtype=np.float32)\n",
    "    \n",
    "    # Load structured movement data\n",
    "    movement_data = load_movement_features(row[\"id\"])\n",
    "    \n",
    "    # Load continuous movement data\n",
    "    continuous_movement_data = load_movement_features_continuous(row[\"id\"])\n",
    "\n",
    "    \"\"\"\n",
    "    movement_data:\n",
    "    {\n",
    "        'Relaxed1_Left_Accelerometer_X': np.array([...]),\n",
    "        'Relaxed1_Left_Accelerometer_Y': np.array([...]),\n",
    "        ...\n",
    "    }\n",
    "    Each key corresponds to a channel, and the value is a 1D numpy array of time series data.\n",
    "    We have a total of 132 keys and each time series has 976 time points.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    for label, args in zip(pipeline_labels, pipeline_args):\n",
    "        # Extract features for each channel unless label is 'questionnaire-only'\n",
    "        features = quest_data\n",
    "        ts_features = {}\n",
    "        if label != 'questionnaire-only':\n",
    "            pipeline_movement_data = movement_data if args['ts_mode'] is None else continuous_movement_data\n",
    "            for channel_name, channel_data in pipeline_movement_data.items():\n",
    "                # Extract features using the specified domain and sampling rate\n",
    "                ts_features[channel_name] = extract_ts_features(label, channel_data, domain=args['domain'], fs=args['fs'])\n",
    "                #print(f\"Extracted {ts_features[channel_name].shape} features from {channel_name} for {label}\")\n",
    "\n",
    "            # Concatenate features from all channels\n",
    "            concat_ts_features = np.concatenate(list(ts_features.values()), axis=0)\n",
    "\n",
    "            # Combine questionnaire data with time series features\n",
    "            features = np.concatenate((features, concat_ts_features), axis=0)\n",
    "        \n",
    "        X_vals[label].append(features.reshape(1, -1))\n",
    "        y_vals[label].append(row['label'])\n",
    "\n",
    "\n",
    "# Combine all samples for each pipeline\n",
    "for label in pipeline_labels:\n",
    "    if X_vals[label]:\n",
    "        X_vals[label] = np.concatenate(X_vals[label], axis=0)\n",
    "        y_vals[label] = np.array(y_vals[label])\n",
    "    else:\n",
    "        X_vals[label] = np.array([])\n",
    "        y_vals[label] = np.array([])\n",
    "\n",
    "for x in X_vals:\n",
    "    print(f\"{x} shape: {X_vals[x].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Labels mapping for reference:\n",
    "# 0: HC\n",
    "# 1: PD\n",
    "# 2: DD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def tune_models(clf, param_grids, X_inner, y_inner, model_name, fit_params=None):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters for each model using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        clf (sklearn classifier): Classifier instance to tune.\n",
    "        param_grids (dict): Dictionary mapping model names to their hyperparameter grids.\n",
    "        X_inner (np.array or pd.DataFrame): Feature matrix for inner CV.\n",
    "        y_inner (np.array): Labels for inner CV.\n",
    "        model_name (str): Name of the model being tuned.\n",
    "        fit_params (dict): Additional parameters for fitting the model.\n",
    "        \n",
    "    Returns:\n",
    "        tuned_results (dict): Dictionary mapping model names to the fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    # Use GridSearchCV for hyperparameter tuning.\n",
    "    scoring = {\"accuracy\": \"accuracy\", \"f1_weighted\": \"f1_weighted\"}\n",
    "    grid = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grids[model_name],\n",
    "        scoring=scoring,\n",
    "        cv=2,       # inner CV folds\n",
    "        n_jobs=-1,\n",
    "        refit=\"accuracy\",  # refit on accuracy\n",
    "        #refit=refit_strategy  # custom refit to pick robust candidate\n",
    "    )\n",
    "    grid.fit(X_inner, y_inner, **fit_params)\n",
    "    return (grid.best_estimator_, grid.best_params_)\n",
    "\n",
    "# TODO: Analyze the refit_strategy function further.\n",
    "#def refit_strategy(cv_results):\n",
    "#    \"\"\"\n",
    "#    Custom refit strategy that uses both accuracy and weighted F1 metrics.\n",
    "#    \n",
    "#    For each hyperparameter candidate (as provided in GridSearchCV’s cv_results_),\n",
    "#    we compute the mean and standard deviation for both 'accuracy' and 'f1_weighted'.\n",
    "#    We then calculate the coefficient of variation (CV) for each metric in percentage.\n",
    "#    The composite score is calculated as:\n",
    "#    \n",
    "#        composite = 0.5*(mean_accuracy + mean_f1_weighted) - lambda_val * 0.5*(CV_accuracy + CV_f1_weighted)\n",
    "#    \n",
    "#    A candidate with a high mean score and a low CV will be preferred.\n",
    "#    \n",
    "#    Parameters:\n",
    "#        cv_results (dict): The cv_results_ dictionary from GridSearchCV. It must contain the keys:\n",
    "#            \"mean_test_accuracy\", \"std_test_accuracy\", \n",
    "#            \"mean_test_f1_weighted\", \"std_test_f1_weighted\".\n",
    "#    \n",
    "#    Returns:\n",
    "#        best_index (int): The index (as in cv_results) of the best candidate.\n",
    "#    \"\"\"\n",
    "#    df = pd.DataFrame(cv_results)\n",
    "#    required_keys = [\"mean_test_accuracy\", \"std_test_accuracy\", \"mean_test_f1_weighted\", \"std_test_f1_weighted\"]\n",
    "#    if not all(key in df.columns for key in required_keys):\n",
    "#        raise ValueError(f\"cv_results must contain the keys: {required_keys}\")\n",
    "#    \n",
    "#    # Means and standard deviations for accuracy and weighted F1.\n",
    "#    mean_acc = df[\"mean_test_accuracy\"]\n",
    "#    std_acc  = df[\"std_test_accuracy\"]\n",
    "#    mean_f1  = df[\"mean_test_f1_weighted\"]\n",
    "#    std_f1   = df[\"std_test_f1_weighted\"]\n",
    "#    \n",
    "#    # Compute coefficient of variation (CV) in percentages.\n",
    "#    cv_acc = (std_acc / mean_acc) * 100\n",
    "#    cv_f1  = (std_f1 / mean_f1) * 100\n",
    "#    \n",
    "#    # Lambda controls the weight given to robustness.\n",
    "#    lambda_val = 0.01\n",
    "#    \n",
    "#    # Composite score: we want high mean and low CV.\n",
    "#    composite = 0.5 * (mean_acc + mean_f1) - lambda_val * 0.5 * (cv_acc + cv_f1)\n",
    "#\n",
    "#    best_index = composite.idxmax()\n",
    "#    return best_index\n",
    "\n",
    "def run_cv(X, y, models, n_splits=5, mode=\"default\", class_weights=None, tune_inner=False, param_grids=None):\n",
    "    \"\"\"\n",
    "    Unified cross-validation runner with optional inner-loop hyperparameter tuning.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.array or pd.DataFrame): Feature matrix.\n",
    "        y (np.array): Labels.\n",
    "        models (dict): Dictionary mapping model names to a tuple: (classifier instance, fit_params dict).\n",
    "                       (If no additional fit parameters are needed, use an empty dict.)\n",
    "        n_splits (int): Number of outer CV folds.\n",
    "        mode (str): One of:\n",
    "            - \"default\": standard CV.\n",
    "            - \"smote\": apply SMOTE oversampling on the training data.\n",
    "            - \"weighted\": for multi-class cost-sensitive learning.\n",
    "            - \"weighted_binary\": for binary cost-sensitive learning (with special handling for XGBoost).\n",
    "        class_weights (dict): Custom class weighting dictionary (e.g., {0: 1.0, 1: 2.0}).\n",
    "        tune_inner (bool): If True and param_grids is provided, perform inner-loop GridSearchCV tuning.\n",
    "        param_grids (dict): Dictionary mapping model names to their hyperparameter grids for tuning.\n",
    "                           Only used if tune_inner is True.\n",
    "        \n",
    "    Returns:\n",
    "        dict: For each model, a dictionary with keys:\n",
    "            \"accuracy\": list of accuracies per outer fold,\n",
    "            \"f1_score\": list of weighted F1 scores per outer fold,\n",
    "            \"log_loss\": list of log losses per outer fold,\n",
    "            \"y_true\": list of true label arrays per fold,\n",
    "            \"y_pred\": list of predicted label arrays per fold,\n",
    "            \"y_pred_proba\": list of predicted probability arrays per fold.\n",
    "    \"\"\"\n",
    "    # Suppress warnings regarding use_label_encoder and feature names\n",
    "    # Ensure X is a DataFrame with valid feature names.\n",
    "    if not hasattr(X, \"columns\"):\n",
    "        X = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Store results as an array of \"folds\" for each model.\n",
    "    results = { name: [] for name in models.keys() }\n",
    "\n",
    "    # Initialize SMOTE if selected.\n",
    "    if mode == \"smote\":\n",
    "        oversampler = SMOTE(random_state=42)\n",
    "\n",
    "    # --- K-fold Outer-loop: Cross-validation ---\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Optionally apply SMOTE.\n",
    "        if mode == \"smote\":\n",
    "            X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # For each model:\n",
    "        for name, (model, fit_params) in models.items():\n",
    "            clf = clone(model)\n",
    "            fold_fit_params = fit_params.copy() if fit_params is not None else {}\n",
    "\n",
    "            # For weighted modes, set class_weight if supported.\n",
    "            if mode in (\"weighted\", \"weighted_binary\") and class_weights is not None:\n",
    "                if 'class_weight' in clf.get_params():\n",
    "                    clf.set_params(class_weight=class_weights)\n",
    "\n",
    "            # Special handling for XGBoost in weighted_binary mode.\n",
    "            if mode == \"weighted_binary\":\n",
    "                try:\n",
    "                    if name == \"XGBoost\" and isinstance(clf, XGBClassifier) and len(np.unique(y_train)) == 2:\n",
    "                        ratio = class_weights.get(1, 1.0) / class_weights.get(0, 1.0)\n",
    "                        clf.set_params(objective='binary:logistic', scale_pos_weight=ratio)\n",
    "                except Exception as e:\n",
    "                    raise ValueError(f\"Error setting scale_pos_weight for XGBoost: {e}\")\n",
    "\n",
    "            # For LightGBM: set eval_set and eval_metric if not already set and verbose to -1.\n",
    "            # This is to avoid printing too much information during training.\n",
    "            if name == \"LightGBM\":\n",
    "                if \"eval_set\" not in fold_fit_params:\n",
    "                    fold_fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "                if \"eval_metric\" not in fold_fit_params:\n",
    "                    fold_fit_params[\"eval_metric\"] = \"logloss\"\n",
    "                clf.set_params(verbose=-1)\n",
    "\n",
    "            # --- K-fold Inner-loop: Hyperparameter tuning ---\n",
    "            hyperparameter_tuning_best_params = None\n",
    "            if tune_inner and param_grids is not None and name in param_grids:\n",
    "                # Perform hyperparameter tuning using GridSearchCV.\n",
    "                print(f\"Tuning hyperparameters for {name}...\")\n",
    "                (best_estimator, best_params) = tune_models(clf, param_grids, X_train, y_train, name, fit_params=fold_fit_params)\n",
    "                clf = best_estimator\n",
    "                hyperparameter_tuning_best_params = best_params\n",
    "            else:\n",
    "                print(f\"Not tuning hyperparameters for {name}.\")\n",
    "                clf.fit(X_train, y_train, **fold_fit_params)\n",
    "\n",
    "            # Evaluate on the outer test set.\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "            # Store each model's results in the \"results\" array, where each outer fold is indexed by k_idx.\n",
    "            # And each element in the results array is a metrics dictionary.\n",
    "            model_metrics = {}\n",
    "            \n",
    "            model_metrics[\"params\"] = hyperparameter_tuning_best_params if hyperparameter_tuning_best_params else \"default\",\n",
    "            model_metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "            model_metrics[\"f1_score\"] = f1_score(y_test, y_pred, average='weighted')\n",
    "            model_metrics[\"log_loss\"] = log_loss(y_test, y_pred_proba)\n",
    "            model_metrics[\"y_true\"] = y_test\n",
    "            model_metrics[\"y_pred\"] = y_pred\n",
    "            model_metrics[\"y_pred_proba\"] = y_pred_proba\n",
    "\n",
    "            print(f\"Model results for {name}:\")\n",
    "            print(f\"Parameters: {model_metrics['params']}\")\n",
    "            print(f\"Accuracy: {model_metrics['accuracy']:.4f}\")\n",
    "            print(f\"F1 Score: {model_metrics['f1_score']:.4f}\")\n",
    "            print(f\"Log Loss: {model_metrics['log_loss']:.4f}\")\n",
    "            \n",
    "            results[name].append(model_metrics)\n",
    "\n",
    "    # Check robustness for each model (using your check_robustness function)\n",
    "    for name in results.keys():\n",
    "        # The metrics stored for each model are in an array of dictionaries, where each dictionary corresponds to a fold.\n",
    "        # We need to extract the metrics from each fold and check their robustness.\n",
    "        acc_values = [results[name][k][\"accuracy\"] for k in range(n_splits)]\n",
    "        f1_values = [results[name][k][\"f1_score\"] for k in range(n_splits)]\n",
    "        ll_values = [results[name][k][\"log_loss\"] for k in range(n_splits)]\n",
    "\n",
    "        print(f\"\\nRobustness for model: {name}\")\n",
    "        acc_robust = check_robustness(\"accuracy\", acc_values)\n",
    "        f1_robust = check_robustness(\"f1_score\", f1_values)\n",
    "        ll_robust = check_robustness(\"log_loss\", ll_values)\n",
    "        if acc_robust and f1_robust and ll_robust:\n",
    "            print(f\"{name} is robust across folds.\\n\")\n",
    "        else:\n",
    "            print(f\"[ERROR] {name} is not robust across folds.\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_cv(results, target_names):\n",
    "    \"\"\"\n",
    "    Aggregates per-fold metrics from a results dictionary and prints overall metrics,\n",
    "    confusion matrix, and classification report using tabulate.\n",
    "    \n",
    "    Parameters:\n",
    "        results (dict): Dictionary mapping model names to a list of per-fold metric dictionaries.\n",
    "                        Each per-fold dictionary must include:\n",
    "                            \"accuracy\": float,\n",
    "                            \"f1_score\": float,\n",
    "                            \"log_loss\": float,\n",
    "                            \"y_true\": true labels for the fold,\n",
    "                            \"y_pred\": predicted labels for the fold,\n",
    "                            \"y_pred_proba\": predicted probability array for the fold,\n",
    "                            \"params\": the model parameters used.\n",
    "        target_names (list): List of class names (e.g., ['HC', 'PD', 'DD']).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of model names to overall metrics including:\n",
    "            \"accuracy_mean\", \"accuracy_std\", \"f1_mean\", \"f1_std\", \n",
    "            \"log_loss_mean\", \"log_loss_std\", \"confusion_matrix\", and \"classification_report\".\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    overall_metrics = {}\n",
    "    table_data = []\n",
    "\n",
    "    # From target_names, print what we are evaluating\n",
    "    print(f\"Evaluating models with target names: {target_names}\")\n",
    "    print(f\"Number of classes: {len(target_names)}\")\n",
    "    print(f\"Classes: {target_names}\")\n",
    "    print(f\"Number of models: {len(results)}\")\n",
    "    print(f\"Models: {list(results.keys())}\")\n",
    "\n",
    "    for name, fold_results in results.items():\n",
    "        # Aggregate per-fold predictions.\n",
    "        y_true_all = np.concatenate([fold[\"y_true\"] for fold in fold_results])\n",
    "        y_pred_all = np.concatenate([fold[\"y_pred\"] for fold in fold_results])\n",
    "        y_pred_proba_all = np.concatenate([fold[\"y_pred_proba\"] for fold in fold_results])\n",
    "        \n",
    "        # Aggregate per-fold metric values.\n",
    "        acc_values = np.array([fold[\"accuracy\"] for fold in fold_results])\n",
    "        f1_values  = np.array([fold[\"f1_score\"] for fold in fold_results])\n",
    "        ll_values  = np.array([fold[\"log_loss\"] for fold in fold_results])\n",
    "        \n",
    "        # Retrieve parameters (assumed constant across folds).\n",
    "        params_val = fold_results[0].get(\"params\", \"default\")\n",
    "        if isinstance(params_val, tuple) and len(params_val) == 1:\n",
    "            params_val = params_val[0]\n",
    "        \n",
    "        # Compute mean and standard deviation for numeric metrics.\n",
    "        acc_mean, acc_std = np.mean(acc_values), np.std(acc_values)\n",
    "        f1_mean,  f1_std  = np.mean(f1_values),  np.std(f1_values)\n",
    "        ll_mean,  ll_std  = np.mean(ll_values),  np.std(ll_values)\n",
    "        \n",
    "        # Compute the overall confusion matrix and classification report.\n",
    "        cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "        clf_report = classification_report(y_true_all, y_pred_all, target_names=target_names, zero_division=0)\n",
    "        \n",
    "        overall_metrics[name] = {\n",
    "            \"params\": params_val,\n",
    "            \"accuracy_mean\": acc_mean,\n",
    "            \"accuracy_std\": acc_std,\n",
    "            \"f1_mean\": f1_mean,\n",
    "            \"f1_std\": f1_std,\n",
    "            \"log_loss_mean\": ll_mean,\n",
    "            \"log_loss_std\": ll_std,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": clf_report,\n",
    "        }\n",
    "        table_data.append([\n",
    "            name,\n",
    "            params_val,\n",
    "            f\"{acc_mean:.4f} ± {acc_std:.4f}\",\n",
    "            f\"{f1_mean:.4f} ± {f1_std:.4f}\",\n",
    "            f\"{ll_mean:.4f} ± {ll_std:.4f}\"\n",
    "        ])\n",
    "        \n",
    "        # Print detailed report for this model.\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"Parameters: {params_val}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(clf_report)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Overall Metrics:\")\n",
    "    print(tabulate(table_data, headers=[\"Model\", \"Params\", \"Accuracy\", \"Weighted F1\", \"Log Loss\"], tablefmt=\"pipe\"))\n",
    "    \n",
    "    return overall_metrics\n",
    "\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        # default: { \"n_estimators\": 100, \"max_depth\": None, \"max_features\": \"sqrt\" }\n",
    "        \"n_estimators\": [100, 300],#, 500],\n",
    "        \"max_depth\": [None, 10],#, 20],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        # default: { \"learning_rate\": 0.3, \"max_depth\": 6, \"subsample\": 1.0 }\n",
    "        \"learning_rate\": [0.1, 0.3],#, 0.01, 0.05],\n",
    "        \"max_depth\": [3, 6],#, 9, 12],\n",
    "        \"subsample\": [0.7, 1.0],#, 0.5, 1.0]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        # default: { \"depth\": 6, \"l2_leaf_reg\": 3 }\n",
    "        \"depth\": [4, 6],#, 10],\n",
    "        \"l2_leaf_reg\": [3, 5],#, 10]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        # default: { \"num_leaves\": 31, \"learning_rate\": 0.1, \"min_child_samples\": 20 }\n",
    "        \"num_leaves\": [20, 31],#, 50, 100],\n",
    "        \"learning_rate\": [0.05, 0.1],#, 0.01, 0.2],\n",
    "        \"min_child_samples\": [10, 20],#, 30, 50]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "     \"RandomForest\": [RandomForestClassifier(random_state=42), {}],\n",
    "     \"XGBoost\": [XGBClassifier(eval_metric='mlogloss', random_state=42), {}],\n",
    "     \"CatBoost\": [CatBoostClassifier(verbose=0, random_state=42), {}],\n",
    "     \"LightGBM\": [LGBMClassifier(random_state=42), {'callbacks': [lgb.early_stopping(10, verbose=0), lgb.log_evaluation(period=0)]}],\n",
    "#     \"LightGBM\": [LGBMClassifier(random_state=42), {}]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos multiclase (PD vs DD vs HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models for basic pipeline...\n",
      "(20, 1218) (20,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.3793\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.3963\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.6945\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9673\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.1495\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5615\n",
      "Log Loss: 1.0076\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.3493\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.4500\n",
      "Log Loss: 0.9210\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3810\n",
      "[f1_score] Metric Standard Deviation: 0.0476\n",
      "[f1_score] Coefficient of Variation (CV): 12.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.2644\n",
      "[log_loss] Metric Standard Deviation: 0.1149\n",
      "[log_loss] Coefficient of Variation (CV): 9.09%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4474\n",
      "[f1_score] Metric Standard Deviation: 0.1141\n",
      "[f1_score] Coefficient of Variation (CV): 25.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.2019\n",
      "[log_loss] Metric Standard Deviation: 0.1944\n",
      "[log_loss] Coefficient of Variation (CV): 16.17%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.5219\n",
      "[log_loss] Metric Standard Deviation: 0.1726\n",
      "[log_loss] Coefficient of Variation (CV): 11.34%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3917\n",
      "[f1_score] Metric Standard Deviation: 0.0583\n",
      "[f1_score] Coefficient of Variation (CV): 14.89%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9441\n",
      "[log_loss] Metric Standard Deviation: 0.0231\n",
      "[log_loss] Coefficient of Variation (CV): 2.45%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.19      0.30      0.23        20\n",
      "weighted avg       0.31      0.50      0.38        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  6  1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.59      0.91      0.71        11\n",
      "          DD       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.31      0.35      0.30        20\n",
      "weighted avg       0.44      0.55      0.46        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  0]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.55      1.00      0.71        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.18      0.33      0.24        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.5000 ± 0.0000 | 0.3810 ± 0.0476 | 1.2644 ± 0.1149 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5500 ± 0.0500 | 0.4474 ± 0.1141 | 1.2019 ± 0.1944 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.5219 ± 0.1726 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.5500 ± 0.0500 | 0.3917 ± 0.0583 | 0.9441 ± 0.0231 |\n",
      "Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\n",
      "Computed class weights: {0: 3.3333333333333335, 1: 0.6060606060606061, 2: 0.9523809523809523}\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.2473\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.3963\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.6945\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.0993\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 300},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.1310\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5615\n",
      "Log Loss: 1.0076\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.3493\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.1385\n",
      "Log Loss: 1.1329\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3810\n",
      "[f1_score] Metric Standard Deviation: 0.0476\n",
      "[f1_score] Coefficient of Variation (CV): 12.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1891\n",
      "[log_loss] Metric Standard Deviation: 0.0582\n",
      "[log_loss] Coefficient of Variation (CV): 4.89%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4474\n",
      "[f1_score] Metric Standard Deviation: 0.1141\n",
      "[f1_score] Coefficient of Variation (CV): 25.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.2019\n",
      "[log_loss] Metric Standard Deviation: 0.1944\n",
      "[log_loss] Coefficient of Variation (CV): 16.17%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.5219\n",
      "[log_loss] Metric Standard Deviation: 0.1726\n",
      "[log_loss] Coefficient of Variation (CV): 11.34%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.2359\n",
      "[f1_score] Metric Standard Deviation: 0.0974\n",
      "[f1_score] Coefficient of Variation (CV): 41.30%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1161\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.51%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.19      0.30      0.23        20\n",
      "weighted avg       0.31      0.50      0.38        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  6  1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.59      0.91      0.71        11\n",
      "          DD       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.31      0.35      0.30        20\n",
      "weighted avg       0.44      0.55      0.46        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 5 6]\n",
      " [0 4 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.45      0.48        11\n",
      "          DD       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.27      0.29      0.28        20\n",
      "weighted avg       0.38      0.40      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.5000 ± 0.0000 | 0.3810 ± 0.0476 | 1.1891 ± 0.0582 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5500 ± 0.0500 | 0.4474 ± 0.1141 | 1.2019 ± 0.1944 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.5219 ± 0.1726 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.4000 ± 0.1000 | 0.2359 ± 0.0974 | 1.1161 ± 0.0168 |\n",
      "Running models for TSFEL-temporal pipeline...\n",
      "(20, 1878) (20,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.0896\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.2758\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.5237\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9673\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 300},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.0126\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4857\n",
      "Log Loss: 1.0018\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5486\n",
      "Log Loss: 1.1423\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.4500\n",
      "Log Loss: 0.9210\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.0511\n",
      "[log_loss] Metric Standard Deviation: 0.0385\n",
      "[log_loss] Coefficient of Variation (CV): 3.66%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4095\n",
      "[f1_score] Metric Standard Deviation: 0.0762\n",
      "[f1_score] Coefficient of Variation (CV): 18.60%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1388\n",
      "[log_loss] Metric Standard Deviation: 0.1370\n",
      "[log_loss] Coefficient of Variation (CV): 12.03%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4410\n",
      "[f1_score] Metric Standard Deviation: 0.1076\n",
      "[f1_score] Coefficient of Variation (CV): 24.41%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.3330\n",
      "[log_loss] Metric Standard Deviation: 0.1907\n",
      "[log_loss] Coefficient of Variation (CV): 14.31%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3917\n",
      "[f1_score] Metric Standard Deviation: 0.0583\n",
      "[f1_score] Coefficient of Variation (CV): 14.89%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9441\n",
      "[log_loss] Metric Standard Deviation: 0.0231\n",
      "[log_loss] Coefficient of Variation (CV): 2.45%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 9 2]\n",
      " [0 6 1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.82      0.67        11\n",
      "          DD       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.27      0.32      0.28        20\n",
      "weighted avg       0.40      0.50      0.43        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 10  1]\n",
      " [ 0  6  1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.35      0.35      0.30        20\n",
      "weighted avg       0.48      0.55      0.46        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  0]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.55      1.00      0.71        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.18      0.33      0.24        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.0511 ± 0.0385 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5000 ± 0.0000 | 0.4095 ± 0.0762 | 1.1388 ± 0.1370 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.5500 ± 0.0500 | 0.4410 ± 0.1076 | 1.3330 ± 0.1907 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.5500 ± 0.0500 | 0.3917 ± 0.0583 | 0.9441 ± 0.0231 |\n",
      "Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\n",
      "Computed class weights: {0: 3.3333333333333335, 1: 0.6060606060606061, 2: 0.9523809523809523}\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'log2', 'n_estimators': 100},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.0846\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.2758\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.5237\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.0993\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 300},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 0.9832\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4857\n",
      "Log Loss: 1.0018\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5486\n",
      "Log Loss: 1.1423\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.1385\n",
      "Log Loss: 1.1329\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.0339\n",
      "[log_loss] Metric Standard Deviation: 0.0507\n",
      "[log_loss] Coefficient of Variation (CV): 4.90%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4095\n",
      "[f1_score] Metric Standard Deviation: 0.0762\n",
      "[f1_score] Coefficient of Variation (CV): 18.60%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1388\n",
      "[log_loss] Metric Standard Deviation: 0.1370\n",
      "[log_loss] Coefficient of Variation (CV): 12.03%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.4410\n",
      "[f1_score] Metric Standard Deviation: 0.1076\n",
      "[f1_score] Coefficient of Variation (CV): 24.41%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.3330\n",
      "[log_loss] Metric Standard Deviation: 0.1907\n",
      "[log_loss] Coefficient of Variation (CV): 14.31%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.2359\n",
      "[f1_score] Metric Standard Deviation: 0.0974\n",
      "[f1_score] Coefficient of Variation (CV): 41.30%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1161\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.51%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 9 2]\n",
      " [0 6 1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.82      0.67        11\n",
      "          DD       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.27      0.32      0.28        20\n",
      "weighted avg       0.40      0.50      0.43        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 10  1]\n",
      " [ 0  6  1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.35      0.35      0.30        20\n",
      "weighted avg       0.48      0.55      0.46        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 5 6]\n",
      " [0 4 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.45      0.48        11\n",
      "          DD       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.27      0.29      0.28        20\n",
      "weighted avg       0.38      0.40      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}   | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.0339 ± 0.0507 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5000 ± 0.0000 | 0.4095 ± 0.0762 | 1.1388 ± 0.1370 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.5500 ± 0.0500 | 0.4410 ± 0.1076 | 1.3330 ± 0.1907 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.4000 ± 0.1000 | 0.2359 ± 0.0974 | 1.1161 ± 0.0168 |\n",
      "Running models for TSFEL-statistical pipeline...\n",
      "(20, 402) (20,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.2308\n",
      "Log Loss: 1.2492\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.4438\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.2308\n",
      "Log Loss: 1.6930\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9673\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.1643\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.1748\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.2795\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.4500\n",
      "Log Loss: 0.9210\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3297\n",
      "[f1_score] Metric Standard Deviation: 0.0989\n",
      "[f1_score] Coefficient of Variation (CV): 30.00%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.2067\n",
      "[log_loss] Metric Standard Deviation: 0.0424\n",
      "[log_loss] Coefficient of Variation (CV): 3.52%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3667\n",
      "[f1_score] Metric Standard Deviation: 0.0333\n",
      "[f1_score] Coefficient of Variation (CV): 9.09%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 1.3093\n",
      "[log_loss] Metric Standard Deviation: 0.1345\n",
      "[log_loss] Coefficient of Variation (CV): 10.27%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3154\n",
      "[f1_score] Metric Standard Deviation: 0.0846\n",
      "[f1_score] Coefficient of Variation (CV): 26.83%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.4862\n",
      "[log_loss] Metric Standard Deviation: 0.2068\n",
      "[log_loss] Coefficient of Variation (CV): 13.91%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3917\n",
      "[f1_score] Metric Standard Deviation: 0.0583\n",
      "[f1_score] Coefficient of Variation (CV): 14.89%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9441\n",
      "[log_loss] Metric Standard Deviation: 0.0231\n",
      "[log_loss] Coefficient of Variation (CV): 2.45%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 8 3]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.73      0.59        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.17      0.24      0.20        20\n",
      "weighted avg       0.28      0.40      0.33        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.53      0.91      0.67        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.18      0.30      0.22        20\n",
      "weighted avg       0.29      0.50      0.37        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 8 3]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.47      0.73      0.57        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.16      0.24      0.19        20\n",
      "weighted avg       0.26      0.40      0.31        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  0]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.55      1.00      0.71        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.18      0.33      0.24        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.4000 ± 0.1000 | 0.3297 ± 0.0989 | 1.2067 ± 0.0424 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5000 ± 0.0000 | 0.3667 ± 0.0333 | 1.3093 ± 0.1345 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.4000 ± 0.1000 | 0.3154 ± 0.0846 | 1.4862 ± 0.2068 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.5500 ± 0.0500 | 0.3917 ± 0.0583 | 0.9441 ± 0.0231 |\n",
      "Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\n",
      "Computed class weights: {0: 3.3333333333333335, 1: 0.6060606060606061, 2: 0.9523809523809523}\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.3631\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.4438\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.2308\n",
      "Log Loss: 1.6930\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.0993\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.3296\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.1748\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.2795\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.1385\n",
      "Log Loss: 1.1329\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3810\n",
      "[f1_score] Metric Standard Deviation: 0.0476\n",
      "[f1_score] Coefficient of Variation (CV): 12.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.3463\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.24%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3667\n",
      "[f1_score] Metric Standard Deviation: 0.0333\n",
      "[f1_score] Coefficient of Variation (CV): 9.09%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 1.3093\n",
      "[log_loss] Metric Standard Deviation: 0.1345\n",
      "[log_loss] Coefficient of Variation (CV): 10.27%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3154\n",
      "[f1_score] Metric Standard Deviation: 0.0846\n",
      "[f1_score] Coefficient of Variation (CV): 26.83%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.4862\n",
      "[log_loss] Metric Standard Deviation: 0.2068\n",
      "[log_loss] Coefficient of Variation (CV): 13.91%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.2359\n",
      "[f1_score] Metric Standard Deviation: 0.0974\n",
      "[f1_score] Coefficient of Variation (CV): 41.30%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1161\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.51%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.19      0.30      0.23        20\n",
      "weighted avg       0.31      0.50      0.38        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.53      0.91      0.67        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.18      0.30      0.22        20\n",
      "weighted avg       0.29      0.50      0.37        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 3}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 8 3]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.47      0.73      0.57        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.16      0.24      0.19        20\n",
      "weighted avg       0.26      0.40      0.31        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 5 6]\n",
      " [0 4 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.45      0.48        11\n",
      "          DD       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.27      0.29      0.28        20\n",
      "weighted avg       0.38      0.40      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.5000 ± 0.0000 | 0.3810 ± 0.0476 | 1.3463 ± 0.0168 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.5000 ± 0.0000 | 0.3667 ± 0.0333 | 1.3093 ± 0.1345 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 3}                                     | 0.4000 ± 0.1000 | 0.3154 ± 0.0846 | 1.4862 ± 0.2068 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.4000 ± 0.1000 | 0.2359 ± 0.0974 | 1.1161 ± 0.0168 |\n",
      "Running models for TSFEL-spectral pipeline...\n",
      "(20, 1362) (20,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9315\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.5468\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 5},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.2006\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9673\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 0.9847\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.1778\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.1625\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.4500\n",
      "Log Loss: 0.9210\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3667\n",
      "[f1_score] Metric Standard Deviation: 0.0333\n",
      "[f1_score] Coefficient of Variation (CV): 9.09%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 0.9581\n",
      "[log_loss] Metric Standard Deviation: 0.0266\n",
      "[log_loss] Coefficient of Variation (CV): 2.78%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "RandomForest is robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.3623\n",
      "[log_loss] Metric Standard Deviation: 0.1845\n",
      "[log_loss] Coefficient of Variation (CV): 13.55%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3810\n",
      "[f1_score] Metric Standard Deviation: 0.0476\n",
      "[f1_score] Coefficient of Variation (CV): 12.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1816\n",
      "[log_loss] Metric Standard Deviation: 0.0191\n",
      "[log_loss] Coefficient of Variation (CV): 1.61%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3917\n",
      "[f1_score] Metric Standard Deviation: 0.0583\n",
      "[f1_score] Coefficient of Variation (CV): 14.89%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9441\n",
      "[log_loss] Metric Standard Deviation: 0.0231\n",
      "[log_loss] Coefficient of Variation (CV): 2.45%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.53      0.91      0.67        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.18      0.30      0.22        20\n",
      "weighted avg       0.29      0.50      0.37        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 5}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.19      0.30      0.23        20\n",
      "weighted avg       0.31      0.50      0.38        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  0]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.55      1.00      0.71        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.18      0.33      0.24        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.5000 ± 0.0000 | 0.3667 ± 0.0333 | 0.9581 ± 0.0266 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.3623 ± 0.1845 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 5}                                     | 0.5000 ± 0.0000 | 0.3810 ± 0.0476 | 1.1816 ± 0.0191 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.5500 ± 0.0500 | 0.3917 ± 0.0583 | 0.9441 ± 0.0231 |\n",
      "Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\n",
      "Computed class weights: {0: 3.3333333333333335, 1: 0.6060606060606061, 2: 0.9523809523809523}\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 0.9779\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 0.2857\n",
      "Log Loss: 1.5468\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 5},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.2006\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.0993\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 0.9802\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4000\n",
      "Log Loss: 1.1778\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4286\n",
      "Log Loss: 1.1625\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.1385\n",
      "Log Loss: 1.1329\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9791\n",
      "[log_loss] Metric Standard Deviation: 0.0012\n",
      "[log_loss] Coefficient of Variation (CV): 0.12%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] RandomForest is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.4500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 11.11%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.3429\n",
      "[f1_score] Metric Standard Deviation: 0.0571\n",
      "[f1_score] Coefficient of Variation (CV): 16.67%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.3623\n",
      "[log_loss] Metric Standard Deviation: 0.1845\n",
      "[log_loss] Coefficient of Variation (CV): 13.55%\n",
      "[log_loss] Model is not robust (CV >= 10%)\n",
      "[ERROR] XGBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.5000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3810\n",
      "[f1_score] Metric Standard Deviation: 0.0476\n",
      "[f1_score] Coefficient of Variation (CV): 12.50%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1816\n",
      "[log_loss] Metric Standard Deviation: 0.0191\n",
      "[log_loss] Coefficient of Variation (CV): 1.61%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.2359\n",
      "[f1_score] Metric Standard Deviation: 0.0974\n",
      "[f1_score] Coefficient of Variation (CV): 41.30%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1161\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.51%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 9 2]\n",
      " [0 7 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.82      0.62        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.17      0.27      0.21        20\n",
      "weighted avg       0.28      0.45      0.34        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 4, 'l2_leaf_reg': 5}\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 10  1]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.56      0.91      0.69        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.19      0.30      0.23        20\n",
      "weighted avg       0.31      0.50      0.38        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 5 6]\n",
      " [0 4 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.45      0.48        11\n",
      "          DD       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.27      0.29      0.28        20\n",
      "weighted avg       0.38      0.40      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 0.9791 ± 0.0012 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.4500 ± 0.0500 | 0.3429 ± 0.0571 | 1.3623 ± 0.1845 |\n",
      "| CatBoost     | {'depth': 4, 'l2_leaf_reg': 5}                                     | 0.5000 ± 0.0000 | 0.3810 ± 0.0476 | 1.1816 ± 0.0191 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.4000 ± 0.1000 | 0.2359 ± 0.0974 | 1.1161 ± 0.0168 |\n",
      "Running models for questionnaire-only pipeline...\n",
      "(20, 30) (20,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.7879\n",
      "Log Loss: 0.6083\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5636\n",
      "Log Loss: 0.8100\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 6, 'l2_leaf_reg': 5},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.6119\n",
      "Log Loss: 0.7620\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 0.9673\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.9000\n",
      "F1 Score: 0.9026\n",
      "Log Loss: 0.6067\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5981\n",
      "Log Loss: 0.7177\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.8355\n",
      "Log Loss: 0.7165\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.4500\n",
      "Log Loss: 0.9210\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.8500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 5.88%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.8452\n",
      "[f1_score] Metric Standard Deviation: 0.0574\n",
      "[f1_score] Coefficient of Variation (CV): 6.79%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 0.6075\n",
      "[log_loss] Metric Standard Deviation: 0.0008\n",
      "[log_loss] Coefficient of Variation (CV): 0.13%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "RandomForest is robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.6000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.5809\n",
      "[f1_score] Metric Standard Deviation: 0.0172\n",
      "[f1_score] Coefficient of Variation (CV): 2.97%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 0.7638\n",
      "[log_loss] Metric Standard Deviation: 0.0462\n",
      "[log_loss] Coefficient of Variation (CV): 6.04%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "XGBoost is robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.7000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 14.29%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.7237\n",
      "[f1_score] Metric Standard Deviation: 0.1118\n",
      "[f1_score] Coefficient of Variation (CV): 15.45%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.7393\n",
      "[log_loss] Metric Standard Deviation: 0.0227\n",
      "[log_loss] Coefficient of Variation (CV): 3.07%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.5500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 9.09%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.3917\n",
      "[f1_score] Metric Standard Deviation: 0.0583\n",
      "[f1_score] Coefficient of Variation (CV): 14.89%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.9441\n",
      "[log_loss] Metric Standard Deviation: 0.0231\n",
      "[log_loss] Coefficient of Variation (CV): 2.45%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 2  0  0]\n",
      " [ 0 10  1]\n",
      " [ 1  1  5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      1.00      0.80         2\n",
      "          PD       0.91      0.91      0.91        11\n",
      "          DD       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.80      0.87      0.83        20\n",
      "weighted avg       0.86      0.85      0.85        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [1 7 3]\n",
      " [1 3 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.50      1.00      0.67         2\n",
      "          PD       0.70      0.64      0.67        11\n",
      "          DD       0.50      0.43      0.46         7\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.57      0.69      0.60        20\n",
      "weighted avg       0.61      0.60      0.59        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 6, 'l2_leaf_reg': 5}\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [2 8 1]\n",
      " [2 1 4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.33      1.00      0.50         2\n",
      "          PD       0.89      0.73      0.80        11\n",
      "          DD       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.67      0.77      0.66        20\n",
      "weighted avg       0.80      0.70      0.72        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  0]\n",
      " [ 0  7  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.55      1.00      0.71        11\n",
      "          DD       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.18      0.33      0.24        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.8500 ± 0.0500 | 0.8452 ± 0.0574 | 0.6075 ± 0.0008 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.6000 ± 0.0000 | 0.5809 ± 0.0172 | 0.7638 ± 0.0462 |\n",
      "| CatBoost     | {'depth': 6, 'l2_leaf_reg': 5}                                     | 0.7000 ± 0.1000 | 0.7237 ± 0.1118 | 0.7393 ± 0.0227 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.5500 ± 0.0500 | 0.3917 ± 0.0583 | 0.9441 ± 0.0231 |\n",
      "Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\n",
      "Computed class weights: {0: 3.3333333333333335, 1: 0.6060606060606061, 2: 0.9523809523809523}\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1558, in fit\n",
      "    valid_sets.append((valid_x, self._le.transform(valid_y)))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py\", line 134, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/utils/_encode.py\", line 242, in _encode\n",
      "    raise ValueError(f\"y contains previously unseen labels: {str(diff)}\")\n",
      "ValueError: y contains previously unseen labels: [0]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.7879\n",
      "Log Loss: 0.6074\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5636\n",
      "Log Loss: 0.8100\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 6, 'l2_leaf_reg': 5},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.6119\n",
      "Log Loss: 0.7620\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.3333\n",
      "Log Loss: 1.0993\n",
      "Tuning hyperparameters for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100},)\n",
      "Accuracy: 0.9000\n",
      "F1 Score: 0.9026\n",
      "Log Loss: 0.6339\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for XGBoost:\n",
      "Parameters: ({'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7},)\n",
      "Accuracy: 0.6000\n",
      "F1 Score: 0.5981\n",
      "Log Loss: 0.7177\n",
      "Tuning hyperparameters for CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for CatBoost:\n",
      "Parameters: ({'depth': 4, 'l2_leaf_reg': 3},)\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.8355\n",
      "Log Loss: 0.7165\n",
      "Tuning hyperparameters for LightGBM...\n",
      "Model results for LightGBM:\n",
      "Parameters: ({'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20},)\n",
      "Accuracy: 0.3000\n",
      "F1 Score: 0.1385\n",
      "Log Loss: 1.1329\n",
      "\n",
      "Robustness for model: RandomForest\n",
      "[accuracy] Metric Mean: 0.8500\n",
      "[accuracy] Metric Standard Deviation: 0.0500\n",
      "[accuracy] Coefficient of Variation (CV): 5.88%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.8452\n",
      "[f1_score] Metric Standard Deviation: 0.0574\n",
      "[f1_score] Coefficient of Variation (CV): 6.79%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 0.6206\n",
      "[log_loss] Metric Standard Deviation: 0.0132\n",
      "[log_loss] Coefficient of Variation (CV): 2.13%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "RandomForest is robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: XGBoost\n",
      "[accuracy] Metric Mean: 0.6000\n",
      "[accuracy] Metric Standard Deviation: 0.0000\n",
      "[accuracy] Coefficient of Variation (CV): 0.00%\n",
      "[accuracy] Model is robust (CV < 10%)\n",
      "[f1_score] Metric Mean: 0.5809\n",
      "[f1_score] Metric Standard Deviation: 0.0172\n",
      "[f1_score] Coefficient of Variation (CV): 2.97%\n",
      "[f1_score] Model is robust (CV < 10%)\n",
      "[log_loss] Metric Mean: 0.7638\n",
      "[log_loss] Metric Standard Deviation: 0.0462\n",
      "[log_loss] Coefficient of Variation (CV): 6.04%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "XGBoost is robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: CatBoost\n",
      "[accuracy] Metric Mean: 0.7000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 14.29%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.7237\n",
      "[f1_score] Metric Standard Deviation: 0.1118\n",
      "[f1_score] Coefficient of Variation (CV): 15.45%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 0.7393\n",
      "[log_loss] Metric Standard Deviation: 0.0227\n",
      "[log_loss] Coefficient of Variation (CV): 3.07%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] CatBoost is not robust across folds.\n",
      "\n",
      "\n",
      "Robustness for model: LightGBM\n",
      "[accuracy] Metric Mean: 0.4000\n",
      "[accuracy] Metric Standard Deviation: 0.1000\n",
      "[accuracy] Coefficient of Variation (CV): 25.00%\n",
      "[accuracy] Model is not robust (CV >= 10%)\n",
      "[f1_score] Metric Mean: 0.2359\n",
      "[f1_score] Metric Standard Deviation: 0.0974\n",
      "[f1_score] Coefficient of Variation (CV): 41.30%\n",
      "[f1_score] Model is not robust (CV >= 10%)\n",
      "[log_loss] Metric Mean: 1.1161\n",
      "[log_loss] Metric Standard Deviation: 0.0168\n",
      "[log_loss] Coefficient of Variation (CV): 1.51%\n",
      "[log_loss] Model is robust (CV < 10%)\n",
      "[ERROR] LightGBM is not robust across folds.\n",
      "\n",
      "Evaluating models with target names: ['HC', 'PD', 'DD']\n",
      "Number of classes: 3\n",
      "Classes: ['HC', 'PD', 'DD']\n",
      "Number of models: 4\n",
      "Models: ['RandomForest', 'XGBoost', 'CatBoost', 'LightGBM']\n",
      "Model: RandomForest\n",
      "Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[ 2  0  0]\n",
      " [ 0 10  1]\n",
      " [ 1  1  5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      1.00      0.80         2\n",
      "          PD       0.91      0.91      0.91        11\n",
      "          DD       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.80      0.87      0.83        20\n",
      "weighted avg       0.86      0.85      0.85        20\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [1 7 3]\n",
      " [1 3 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.50      1.00      0.67         2\n",
      "          PD       0.70      0.64      0.67        11\n",
      "          DD       0.50      0.43      0.46         7\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.57      0.69      0.60        20\n",
      "weighted avg       0.61      0.60      0.59        20\n",
      "\n",
      "\n",
      "\n",
      "Model: CatBoost\n",
      "Parameters: {'depth': 6, 'l2_leaf_reg': 5}\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [2 8 1]\n",
      " [2 1 4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.33      1.00      0.50         2\n",
      "          PD       0.89      0.73      0.80        11\n",
      "          DD       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.67      0.77      0.66        20\n",
      "weighted avg       0.80      0.70      0.72        20\n",
      "\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "Parameters: {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20}\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 5 6]\n",
      " [0 4 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00         2\n",
      "          PD       0.50      0.45      0.48        11\n",
      "          DD       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.27      0.29      0.28        20\n",
      "weighted avg       0.38      0.40      0.39        20\n",
      "\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "| Model        | Params                                                             | Accuracy        | Weighted F1     | Log Loss        |\n",
      "|:-------------|:-------------------------------------------------------------------|:----------------|:----------------|:----------------|\n",
      "| RandomForest | {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}   | 0.8500 ± 0.0500 | 0.8452 ± 0.0574 | 0.6206 ± 0.0132 |\n",
      "| XGBoost      | {'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.7}           | 0.6000 ± 0.0000 | 0.5809 ± 0.0172 | 0.7638 ± 0.0462 |\n",
      "| CatBoost     | {'depth': 6, 'l2_leaf_reg': 5}                                     | 0.7000 ± 0.1000 | 0.7237 ± 0.1118 | 0.7393 ± 0.0227 |\n",
      "| LightGBM     | {'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 20} | 0.4000 ± 0.1000 | 0.2359 ± 0.0974 | 1.1161 ± 0.0168 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 16.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py\", line 1518, in fit\n",
      "    self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}\n",
      "                          ~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/santiago/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x11aa24360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1039bc360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107ae4360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107a0c360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107654360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107810360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x109374360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106a24360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106f1c360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103b0c360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "for x in X_vals:\n",
    "    X = X_vals[x]\n",
    "    y = y_vals[x]\n",
    "    print(f\"Running models for {x} pipeline...\")\n",
    "    print(X.shape, y.shape)\n",
    "    print(y[:10])\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification (no changes): PD vs DD vs HC\n",
    "    # -----------------------------------------------------------------------------\n",
    "    print(len(np.unique(y)))\n",
    "    if len(np.unique(y)) == 3:\n",
    "        print(\"Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\")\n",
    "        results_default = run_cv(X, y, models, n_splits=2, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "        overall_default = evaluate_cv(results_default, target_names=['HC', 'PD', 'DD'])\n",
    "    else:\n",
    "        print(\"Multi-class classification (PD vs DD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification with SMOTE: PD vs DD vs HC\n",
    "    # -----------------------------------------------------------------------------\n",
    "    #if len(np.unique(y)) == 3:\n",
    "    #    print(\"Performing multi-class classification (PD vs DD vs HC) with SMOTE...\")\n",
    "    #    results_smote = run_cv(X, y, models, n_splits=2, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "    #    overall_smote = evaluate_cv(results_smote, target_names=['HC', 'PD', 'DD'])\n",
    "    #else:\n",
    "    #    print(\"Multi-class classification with SMOTE is not possible with the current labels.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification with Cost-Sensitive Learning (PD vs DD vs HC)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    if len(np.unique(y)) == 3:\n",
    "        print(\"Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\")\n",
    "        classes = np.unique(y)\n",
    "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "        class_weights_multi = dict(zip(classes, weights))\n",
    "        print(\"Computed class weights:\", class_weights_multi)\n",
    "        \n",
    "        results_weighted = run_cv(\n",
    "            X, y,\n",
    "            models,\n",
    "            n_splits=2,\n",
    "            mode=\"weighted\",\n",
    "            class_weights=class_weights_multi,\n",
    "            tune_inner=True,\n",
    "            param_grids=param_grids\n",
    "        )\n",
    "        overall_weighted = evaluate_cv(results_weighted, target_names=['HC', 'PD', 'DD'])\n",
    "    else:\n",
    "        print(\"Multi-class classification with cost-sensitive learning is not possible with the current labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Binarios (PD vs DD) / (PD vs HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Labels mapping for reference:\n",
    "# 0: HC\n",
    "# 1: PD\n",
    "# 2: DD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD (Default Mode)\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD [Default Mode]...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0, DD (2) becomes 1\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "    \n",
    "    results_pd_dd_default = run_cv(X_pd_dd, y_pd_dd_binary, models, n_splits=5, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_dd_default = evaluate_cv(results_pd_dd_default, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"\\nBinary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC (Default Mode)\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC [Default Mode]...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    results_pd_hc_default = run_cv(X_pd_hc, y_pd_hc, models, n_splits=5, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_hc_default = evaluate_cv(results_pd_hc_default, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"\\nBinary classification (PD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD with SMOTE\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD with SMOTE...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0, DD (2) becomes 1\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "    \n",
    "    results_pd_dd_smote = run_cv(X_pd_dd, y_pd_dd_binary, models, n_splits=5, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_dd_smote = evaluate_cv(results_pd_dd_smote, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC with SMOTE\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC with SMOTE...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    results_pd_hc_smote = run_cv(X_pd_hc, y_pd_hc, models, n_splits=5, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_hc_smote = evaluate_cv(results_pd_hc_smote, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD with Cost-Sensitive Learning (Weighted Binary Mode)\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD with cost-sensitive learning...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0 and DD (2) becomes 1.\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "\n",
    "    # Compute balanced class weights from the original y_pd_dd\n",
    "    classes = np.unique(y_pd_dd)  # Typically [1, 2]\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_pd_dd)\n",
    "    # Create a dictionary mapping original classes to their weight.\n",
    "    class_weights_pd_dd = dict(zip(classes, weights))\n",
    "    # Remap keys to reflect the new labels: PD becomes 0, DD becomes 1.\n",
    "    class_weights_pd_dd = {k - 1: v for k, v in class_weights_pd_dd.items()}\n",
    "    print(\"Computed class weights for PD vs DD:\", class_weights_pd_dd)\n",
    "    \n",
    "    results_pd_dd_weighted = run_cv(\n",
    "        X_pd_dd,\n",
    "        y_pd_dd_binary,\n",
    "        models,\n",
    "        n_splits=5,\n",
    "        mode=\"weighted_binary\",\n",
    "        class_weights=class_weights_pd_dd,\n",
    "        tune_inner=True,\n",
    "        param_grids=param_grids\n",
    "    )\n",
    "    overall_pd_dd_weighted = evaluate_cv(results_pd_dd_weighted, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC with Cost-Sensitive Learning (Weighted Binary Mode)\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC with cost-sensitive learning...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    # Compute balanced class weights from the current training subset.\n",
    "    # Here, we assume that in PD vs HC, class 0 = HC and class 1 = PD.\n",
    "    classes = np.unique(y_pd_hc)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_pd_hc)\n",
    "    class_weights_pd_hc = dict(zip(classes, weights))\n",
    "    print(\"Computed class weights:\", class_weights_pd_hc)\n",
    "    \n",
    "    results_pd_hc_weighted = run_cv(\n",
    "        X_pd_hc,\n",
    "        y_pd_hc,\n",
    "        models,\n",
    "        n_splits=5,\n",
    "        mode=\"weighted_binary\",\n",
    "        class_weights=class_weights_pd_hc,\n",
    "        tune_inner=True,\n",
    "        param_grids=param_grids\n",
    "    )\n",
    "    overall_pd_hc_weighted = evaluate_cv(results_pd_hc_weighted, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs HC) is not possible with the current labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
