{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import tsfel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, f1_score, log_loss, confusion_matrix, classification_report)\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_robustness(metric_name, metric_values, threshold_percent=10):\n",
    "    \"\"\"\n",
    "    Check the robustness of a model based on k-fold metric values.\n",
    "    \n",
    "    A model is considered robust if the coefficient of variation (CV),\n",
    "    defined as (standard deviation / mean) * 100, is less than threshold_percent.\n",
    "    \n",
    "    Parameters:\n",
    "        metric_values (list or np.array): List/array of metric values from each fold.\n",
    "        threshold_percent (float): The maximum allowed CV percentage (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the model is robust (CV < threshold_percent), False otherwise.\n",
    "    \"\"\"\n",
    "    metric_values = np.array(metric_values)\n",
    "    mean_val = np.mean(metric_values)\n",
    "    std_val = np.std(metric_values)\n",
    "    \n",
    "    # Avoid division by zero:\n",
    "    if mean_val == 0:\n",
    "        cv = float('inf')\n",
    "    else:\n",
    "        cv = (std_val / mean_val) * 100\n",
    "\n",
    "    print(f\"[{metric_name}] Metric Mean: {mean_val:.4f}\")\n",
    "    print(f\"[{metric_name}] Metric Standard Deviation: {std_val:.4f}\")\n",
    "    print(f\"[{metric_name}] Coefficient of Variation (CV): {cv:.2f}%\")\n",
    "    \n",
    "    if cv < threshold_percent:\n",
    "        print(f\"[{metric_name}] Model is robust (CV < {threshold_percent}%)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"[{metric_name}] Model is not robust (CV >= {threshold_percent}%)\")\n",
    "        return False\n",
    "    \n",
    "def get_movement_data(subject_id, base_path, sampling_rate):\n",
    "    # File path handling\n",
    "    path = Path(base_path) / f'{subject_id}_ml.bin'\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Movement data not found for subject {subject_id}\")\n",
    "    \n",
    "    # Load raw data\n",
    "    raw_data = np.fromfile(path, dtype=np.float32)\n",
    "    \n",
    "    # Channel configuration\n",
    "    tasks = [\"Relaxed1\", \"Relaxed2\", \"RelaxedTask1\", \"RelaxedTask2\", \n",
    "             \"StretchHold\", \"HoldWeight\", \"DrinkGlas\", \"CrossArms\", \n",
    "             \"TouchNose\", \"Entrainment1\", \"Entrainment2\"]\n",
    "    wrists = [\"Left\", \"Right\"]\n",
    "    sensors = [\"Accelerometer\", \"Gyroscope\"]\n",
    "    axes = [\"X\", \"Y\", \"Z\"]\n",
    "    \n",
    "    # Calculate expected parameters\n",
    "    n_channels = len(tasks) * len(wrists) * len(sensors) * len(axes)\n",
    "\n",
    "    # Even though the duration was 10.24 per assessment, the first ~0.5 seconds are not used and thus\n",
    "    # the preprocessed data has only 9.76 seconds of data\n",
    "    expected_duration = 9.76  # seconds per assessment\n",
    "    expected_timepoints = int(expected_duration * sampling_rate)  # 976\n",
    "    \n",
    "    # Validate data size\n",
    "    expected_size = n_channels * expected_timepoints\n",
    "    #print(f\"Expected size: {expected_size} elements\")\n",
    "    if len(raw_data) != expected_size:\n",
    "        raise ValueError(f\"Unexpected data size for {subject_id}: \"\n",
    "                         f\"Got {len(raw_data)} elements, expected {expected_size}\")\n",
    "    \n",
    "    return {\n",
    "        'tasks': tasks,\n",
    "        'wrists': wrists,\n",
    "        'sensors': sensors,\n",
    "        'axes': axes,\n",
    "        'raw_data': raw_data,\n",
    "        'timepoints': expected_timepoints,\n",
    "    }\n",
    "    \n",
    "def load_movement_features(subject_id, base_path='../../data/preprocessed/movement/', sampling_rate=100):\n",
    "    \"\"\"\n",
    "    Load and structure movement data from binary files with proper validation\n",
    "    \n",
    "    Args:\n",
    "        subject_id (str): Subject identifier (e.g., '001')\n",
    "        base_path (str): Base directory for movement data\n",
    "        sampling_rate (int): Sampling rate in Hz (used for validation)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Structured data with keys as channel names and values as time series arrays\n",
    "    \"\"\"\n",
    "    movement_data = get_movement_data(subject_id, base_path, sampling_rate)\n",
    "    tasks = movement_data['tasks']\n",
    "    wrists = movement_data['wrists']\n",
    "    sensors = movement_data['sensors']\n",
    "    axes = movement_data['axes']\n",
    "    raw_data = movement_data['raw_data']\n",
    "    timepoints = movement_data['timepoints']\n",
    "    \n",
    "    # Reshape and structure the data\n",
    "    structured_data = {}\n",
    "    channel_idx = 0\n",
    "    \n",
    "    for task in tasks:\n",
    "        for wrist in wrists:\n",
    "            for sensor in sensors:\n",
    "                for axis in axes:\n",
    "                    # Extract channel data\n",
    "                    start = channel_idx * timepoints\n",
    "                    end = (channel_idx + 1) * timepoints\n",
    "                    \n",
    "                    # Create channel name\n",
    "                    channel_name = f\"{task}_{wrist}_{sensor.split(' ')[0]}_{axis}\"\n",
    "                    \n",
    "                    structured_data[channel_name] = raw_data[start:end]\n",
    "                    \n",
    "                    channel_idx += 1\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "def load_movement_features_continuous(subject_id, base_path='../../data/preprocessed/movement/', sampling_rate=100):\n",
    "    \"\"\"\n",
    "    Load and structure movement data by concatenating across tasks for each (wrist, sensor, axis).\n",
    "    \n",
    "    Instead of one series per task, produces one long series per channel (wrist/sensor/axis)\n",
    "    by appending each taskâ€™s trimmed data end-to-end.\n",
    "    \n",
    "    Args:\n",
    "        subject_id (str): Subject identifier (e.g., '001')\n",
    "        base_path (str): Base directory for movement data\n",
    "        sampling_rate (int): Sampling rate in Hz (used for validation)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are \"{wrist}_{sensor}_{axis}\", values are 1D numpy arrays of length\n",
    "              (expected_timepoints - skip) * n_tasks\n",
    "    \"\"\"\n",
    "    movement_data = get_movement_data(subject_id, base_path, sampling_rate)\n",
    "    tasks = movement_data['tasks']\n",
    "    wrists = movement_data['wrists']\n",
    "    sensors = movement_data['sensors']\n",
    "    axes = movement_data['axes']\n",
    "    raw_data = movement_data['raw_data']\n",
    "    timepoints = movement_data['timepoints']\n",
    "    \n",
    "    # Prepare container: one list per (wrist, sensor, axis)\n",
    "    cont = {\n",
    "        f\"{wrist}_{sensor}_{axis}\": []\n",
    "        for wrist in wrists\n",
    "        for sensor in sensors\n",
    "        for axis in axes\n",
    "    }\n",
    "    \n",
    "    # Slice raw per (task, wrist, sensor, axis), trim, and append\n",
    "    idx = 0\n",
    "    for task in tasks:\n",
    "        for wrist in wrists:\n",
    "            for sensor in sensors:\n",
    "                for axis in axes:\n",
    "                    start = idx * timepoints\n",
    "                    end = start + timepoints\n",
    "                    segment = raw_data[start:end]\n",
    "                    key = f\"{wrist}_{sensor}_{axis}\"\n",
    "                    cont[key].append(segment)\n",
    "                    idx += 1\n",
    "    \n",
    "    # Concatenate per key\n",
    "    for key, chunks in cont.items():\n",
    "        cont[key] = np.concatenate(chunks)\n",
    "    \n",
    "    return cont\n",
    "\n",
    "def extract_tsfel_ts_features(channel_data, domain=None, fs=100):\n",
    "    \"\"\"\n",
    "    Extract TSFEL features from a single-channel time series.\n",
    "    \n",
    "    Args:\n",
    "        channel_data (np.ndarray): 1D array of time series values.\n",
    "        domain: (str): Domain of features to extract (default: 'all').\n",
    "            - 'statistical', 'temporal', 'spectral', 'fractal': Includes the corresponding feature domain.\n",
    "            - 'all': Includes all available feature domains.\n",
    "            - list of str: A combination of the above strings, e.g., ['statistical', 'temporal'].\n",
    "            - None: By default, includes the 'statistical', 'temporal', and 'spectral' domains.\n",
    "        fs (int): Sampling frequency (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of TSFEL features.\n",
    "    \"\"\"\n",
    "    # Obtain a default configuration covering all domains.\n",
    "    cfg = tsfel.get_features_by_domain(domain)\n",
    "\n",
    "    # Extract features; the result is a DataFrame with one row.\n",
    "    features_df = tsfel.time_series_features_extractor(cfg, channel_data, fs=fs, verbose=0)\n",
    "    \n",
    "    # Flatten to 1D numpy array and return.\n",
    "    return features_df.values.flatten()\n",
    "\n",
    "def extract_ts_features(label, channel_data, domain=None, fs=None):\n",
    "    if label == 'basic':\n",
    "        features = [\n",
    "            np.mean(channel_data), # Mean of the signal\n",
    "            np.std(channel_data), # Standard deviation\n",
    "            np.min(channel_data), # Minimum value\n",
    "            np.max(channel_data), # Maximum value\n",
    "            np.percentile(channel_data, 25), # 25th percentile\n",
    "            np.percentile(channel_data, 75), # 75th percentile\n",
    "            np.var(channel_data), # Variance\n",
    "            len(np.where(np.diff(np.sign(channel_data)))[0]) / len(channel_data),  # Zero-crossing rate\n",
    "            np.sqrt(np.mean(channel_data**2))  # Root Mean Square (RMS)\n",
    "        ]\n",
    "\n",
    "        # Return features as a numpy array\n",
    "        features = np.array(features)\n",
    "        return features\n",
    "    else:\n",
    "        return extract_tsfel_ts_features(channel_data, domain=domain, fs=fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Requisite: Python 3.12 (por catboost). brew install libomp para xgboost\n",
    "\n",
    "tsfel explicaciones: https://github.com/fraunhoferportugal/tsfel/blob/v0.1.9/tsfel/feature_extraction/features.json\n",
    "\n",
    "En base a los datos preprocesados, entrenaremos modelos de clasificacion bajo distintos escenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:01<07:52,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs\n",
      "100\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/469 [00:01<07:45,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "None\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n",
      "fs\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/469 [00:03<12:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs\n",
      "100\n",
      "fs\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(args[\u001b[33m'\u001b[39m\u001b[33mfs\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ts_features[channel_name] = \u001b[43mextract_ts_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdomain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m#print(f\"Extracted {ts_features[channel_name].shape} features from {channel_name} for {label}\")\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Concatenate features from all channels\u001b[39;00m\n\u001b[32m     83\u001b[39m concat_ts_features = np.concatenate(\u001b[38;5;28mlist\u001b[39m(ts_features.values()), axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 212\u001b[39m, in \u001b[36mextract_ts_features\u001b[39m\u001b[34m(label, channel_data, domain, fs)\u001b[39m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextract_tsfel_ts_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mextract_tsfel_ts_features\u001b[39m\u001b[34m(channel_data, domain, fs)\u001b[39m\n\u001b[32m    186\u001b[39m cfg = tsfel.get_features_by_domain(domain)\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Extract features; the result is a DataFrame with one row.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m features_df = \u001b[43mtsfel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime_series_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Flatten to 1D numpy array and return.\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m features_df.values.flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/tsfel/feature_extraction/calc_features.py:377\u001b[39m, in \u001b[36mtime_series_features_extractor\u001b[39m\u001b[34m(config, timeseries, fs, window_size, overlap, verbose, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\n\u001b[32m    373\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn_jobs value is not valid. \u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mChoose an integer value or None for no multiprocessing.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    374\u001b[39m         )\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# single window\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     features_final = \u001b[43mcalc_window_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43msingle_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# Assuring the same feature extraction order\u001b[39;00m\n\u001b[32m    388\u001b[39m features_final = features_final.reindex(\u001b[38;5;28msorted\u001b[39m(features_final.columns), axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/tsfel/feature_extraction/calc_features.py:510\u001b[39m, in \u001b[36mcalc_window_features\u001b[39m\u001b[34m(config, window, fs, verbose, single_window, **kwargs)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Eval feature results\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_axis:\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     eval_result = \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc_total\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparameters_total\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     eval_result = np.array([eval_result])\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(header_names)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/tsfel/feature_extraction/features.py:1757\u001b[39m, in \u001b[36mwavelet_var\u001b[39m\u001b[34m(signal, fs, wavelet, max_width)\u001b[39m\n\u001b[32m   1754\u001b[39m max_width = \u001b[38;5;28mint\u001b[39m(max_width)\n\u001b[32m   1755\u001b[39m widths = np.arange(\u001b[32m1\u001b[39m, max_width)\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m coeffs, frequencies = \u001b[43mcontinuous_wavelet_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1758\u001b[39m f_keys = np.round(frequencies, \u001b[32m2\u001b[39m).astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   1760\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m: [f + \u001b[33m\"\u001b[39m\u001b[33mHz\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m f_keys], \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m: np.var(coeffs, axis=\u001b[32m1\u001b[39m)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/tsfel/feature_extraction/features_utils.py:371\u001b[39m, in \u001b[36mcontinuous_wavelet_transform\u001b[39m\u001b[34m(signal, fs, wavelet, widths)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontinuous_wavelet_transform\u001b[39m(signal, fs, wavelet=\u001b[33m\"\u001b[39m\u001b[33mmexh\u001b[39m\u001b[33m\"\u001b[39m, widths=np.arange(\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m)):\n\u001b[32m    352\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Computes CWT (continuous wavelet transform) of the signal.\u001b[39;00m\n\u001b[32m    353\u001b[39m \n\u001b[32m    354\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m \u001b[33;03m        matrix with size (len(widths),len(signal))\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     coefficients, frequencies = \u001b[43mpywt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcwt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_period\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m coefficients, frequencies\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/pywt/_cwt.py:161\u001b[39m, in \u001b[36mcwt\u001b[39m\u001b[34m(data, scales, wavelet, sampling_period, method, axis)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mconv\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m         conv = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_psi_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m         \u001b[38;5;66;03m# batch convolution via loop\u001b[39;00m\n\u001b[32m    164\u001b[39m         conv_shape = \u001b[38;5;28mlist\u001b[39m(data.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/numpy/core/numeric.py:834\u001b[39m, in \u001b[36mconvolve\u001b[39m\u001b[34m(a, v, mode)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) == \u001b[32m0\u001b[39m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mv cannot be empty\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cargar metadatos\n",
    "file_list = pd.read_csv('../../data/preprocessed/file_list.csv',  dtype={'id': str})\n",
    "\n",
    "movement_data_per_subject = {}\n",
    "sampling_rate = 100\n",
    "\n",
    "# In the normal case, we have 132 channels and every channel has 976 time points (giving 128832 which is correct)\n",
    "\n",
    "# Create multiple cases so we can check each model independently:\n",
    "# 1. Basic statistical features (Reduce 128832 features [976 features p/c] to 1188 features [9 features p/c]) + questionnaire data\n",
    "# 2. TSFEL only temporal features (Reduce 128832 features [976 features p/c] to 1848 features [14 features p/c]  + questionnaire data\n",
    "# 3. [NOT DOING - TOO BIG] TSFEL only statistical features (Reduce 128832 features [976 features p/c] to 4092 features [31 features p/c]  + questionnaire data\n",
    "# 4. [NOT DOING - TOO BIG] TSFEL only spectral features (Reduce 128832 features [976 features p/c] to 14652 features [111 features p/c]  + questionnaire data\n",
    "# 5. Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "# In the continuous case, we have 12 channels but every channel has 10736 time points (giving 128832 which is correct)\n",
    "\n",
    "# 1. [NOT DOING - DONE ON NORMAL] Basic statistical features (Reduce 128832 features [10736 features p/c] to 108 features [9 features p/c]) + questionnaire data\n",
    "# 2. [NOT DOING - DONE ON NORMAL] TSFEL only temporal features (Reduce 128832 features [10736 features p/c] to 168 features [14 features p/c]  + questionnaire data\n",
    "# 3. TSFEL only statistical features (Reduce 128832 features [10736 features p/c] to 372 features [31 features p/c]  + questionnaire data\n",
    "# 4. TSFEL only spectral features (Reduce 128832 features [10736 features p/c] to 1332 features [111 features p/c]  + questionnaire data\n",
    "# 5. Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "# For efficiency purposes, we do\n",
    "# 1. (Normal) Basic statistical features (Reduce 128832 features [976 features p/c] to 1188 features [9 features p/c]) + questionnaire data\n",
    "# 2. (Normal) TSFEL only temporal features (Reduce 128832 features [976 features p/c] to 1848 features [14 features p/c]  + questionnaire data\n",
    "# 3. (Cont)   TSFEL only statistical features (Reduce 128832 features [10736 features p/c] to 372 features [31 features p/c]  + questionnaire data\n",
    "# 4. (Cont)   TSFEL only spectral features (Reduce 128832 features [10736 features p/c] to 1332 features [111 features p/c]  + questionnaire data\n",
    "# 5. (N/A)    Only questionnaire data (Uses only the questionnaire data, no movement data), used as a baseline\n",
    "\n",
    "pipeline_labels = ['basic', 'TSFEL-temporal', 'TSFEL-statistical', 'TSFEL-spectral', 'questionnaire-only']\n",
    "\n",
    "pipeline_args = [\n",
    "    {'domain': None, 'fs': None, 'ts_mode': None},  # Basic statistical features\n",
    "    {'domain': 'temporal', 'fs': sampling_rate, 'ts_mode': None},  # TSFEL-temporal\n",
    "    {'domain': 'statistical', 'fs': sampling_rate, 'ts_mode': 'continuous'},  # TSFEL-statistical\n",
    "    {'domain': 'spectral', 'fs': sampling_rate, 'ts_mode': 'continuous'},  # TSFEL-spectral\n",
    "    None,  # Questionnaire-only\n",
    "]\n",
    "\n",
    "# X must be 2D (samples, features)\n",
    "X_vals = {label: [] for label in pipeline_labels}\n",
    "y_vals = {label: [] for label in pipeline_labels}\n",
    "\n",
    "# First, load timeseries data and extract features\n",
    "for _, row in tqdm(file_list.iterrows(), total=len(file_list)):\n",
    "    # Cargar cuestionario\n",
    "    quest_data = np.fromfile(f'../../data/preprocessed/questionnaire/{row[\"id\"]}_ml.bin', \n",
    "                           dtype=np.float32)\n",
    "    \n",
    "    # Load structured movement data\n",
    "    movement_data = load_movement_features(row[\"id\"])\n",
    "    \n",
    "    # Load continuous movement data\n",
    "    continuous_movement_data = load_movement_features_continuous(row[\"id\"])\n",
    "\n",
    "    \"\"\"\n",
    "    movement_data:\n",
    "    {\n",
    "        'Relaxed1_Left_Accelerometer_X': np.array([...]),\n",
    "        'Relaxed1_Left_Accelerometer_Y': np.array([...]),\n",
    "        ...\n",
    "    }\n",
    "    Each key corresponds to a channel, and the value is a 1D numpy array of time series data.\n",
    "    We have a total of 132 keys and each time series has 976 time points.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    for label, args in zip(pipeline_labels, pipeline_args):\n",
    "        # Extract features for each channel unless label is 'questionnaire-only'\n",
    "        features = quest_data\n",
    "        ts_features = {}\n",
    "        if label != 'questionnaire-only':\n",
    "            pipeline_movement_data = movement_data if args['ts_mode'] is None else continuous_movement_data\n",
    "            for channel_name, channel_data in pipeline_movement_data.items():\n",
    "                # Extract features using the specified domain and sampling rate\n",
    "                print(\"fs\")\n",
    "                print(args['fs'])\n",
    "                ts_features[channel_name] = extract_ts_features(label, channel_data, domain=args['domain'], fs=args['fs'])\n",
    "                #print(f\"Extracted {ts_features[channel_name].shape} features from {channel_name} for {label}\")\n",
    "\n",
    "            # Concatenate features from all channels\n",
    "            concat_ts_features = np.concatenate(list(ts_features.values()), axis=0)\n",
    "\n",
    "            # Combine questionnaire data with time series features\n",
    "            features = np.concatenate((features, concat_ts_features), axis=0)\n",
    "        \n",
    "        X_vals[label].append(features.reshape(1, -1))\n",
    "        y_vals[label].append(row['label'])\n",
    "\n",
    "\n",
    "# Combine all samples for each pipeline\n",
    "for label in pipeline_labels:\n",
    "    if X_vals[label]:\n",
    "        X_vals[label] = np.concatenate(X_vals[label], axis=0)\n",
    "        y_vals[label] = np.array(y_vals[label])\n",
    "    else:\n",
    "        X_vals[label] = np.array([])\n",
    "        y_vals[label] = np.array([])\n",
    "\n",
    "for x in X_vals:\n",
    "    print(f\"{x} shape: {X_vals[x].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Labels mapping for reference:\n",
    "# 0: HC\n",
    "# 1: PD\n",
    "# 2: DD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def tune_models(clf, param_grids, X_inner, y_inner, model_name, fit_params=None):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters for each model using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        clf (sklearn classifier): Classifier instance to tune.\n",
    "        param_grids (dict): Dictionary mapping model names to their hyperparameter grids.\n",
    "        X_inner (np.array or pd.DataFrame): Feature matrix for inner CV.\n",
    "        y_inner (np.array): Labels for inner CV.\n",
    "        model_name (str): Name of the model being tuned.\n",
    "        fit_params (dict): Additional parameters for fitting the model.\n",
    "        \n",
    "    Returns:\n",
    "        tuned_results (dict): Dictionary mapping model names to the fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    # Use GridSearchCV for hyperparameter tuning.\n",
    "    scoring = {\"accuracy\": \"accuracy\", \"f1_weighted\": \"f1_weighted\"}\n",
    "    grid = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grids[model_name],\n",
    "        scoring=scoring,\n",
    "        cv=3,       # inner CV folds\n",
    "        n_jobs=-1,\n",
    "        refit=\"accuracy\",  # refit on accuracy\n",
    "        #refit=refit_strategy  # custom refit to pick robust candidate\n",
    "    )\n",
    "    grid.fit(X_inner, y_inner, **fit_params)\n",
    "    return (grid.best_estimator_, grid.best_params_)\n",
    "\n",
    "# TODO: Analyze the refit_strategy function further.\n",
    "#def refit_strategy(cv_results):\n",
    "#    \"\"\"\n",
    "#    Custom refit strategy that uses both accuracy and weighted F1 metrics.\n",
    "#    \n",
    "#    For each hyperparameter candidate (as provided in GridSearchCVâ€™s cv_results_),\n",
    "#    we compute the mean and standard deviation for both 'accuracy' and 'f1_weighted'.\n",
    "#    We then calculate the coefficient of variation (CV) for each metric in percentage.\n",
    "#    The composite score is calculated as:\n",
    "#    \n",
    "#        composite = 0.5*(mean_accuracy + mean_f1_weighted) - lambda_val * 0.5*(CV_accuracy + CV_f1_weighted)\n",
    "#    \n",
    "#    A candidate with a high mean score and a low CV will be preferred.\n",
    "#    \n",
    "#    Parameters:\n",
    "#        cv_results (dict): The cv_results_ dictionary from GridSearchCV. It must contain the keys:\n",
    "#            \"mean_test_accuracy\", \"std_test_accuracy\", \n",
    "#            \"mean_test_f1_weighted\", \"std_test_f1_weighted\".\n",
    "#    \n",
    "#    Returns:\n",
    "#        best_index (int): The index (as in cv_results) of the best candidate.\n",
    "#    \"\"\"\n",
    "#    df = pd.DataFrame(cv_results)\n",
    "#    required_keys = [\"mean_test_accuracy\", \"std_test_accuracy\", \"mean_test_f1_weighted\", \"std_test_f1_weighted\"]\n",
    "#    if not all(key in df.columns for key in required_keys):\n",
    "#        raise ValueError(f\"cv_results must contain the keys: {required_keys}\")\n",
    "#    \n",
    "#    # Means and standard deviations for accuracy and weighted F1.\n",
    "#    mean_acc = df[\"mean_test_accuracy\"]\n",
    "#    std_acc  = df[\"std_test_accuracy\"]\n",
    "#    mean_f1  = df[\"mean_test_f1_weighted\"]\n",
    "#    std_f1   = df[\"std_test_f1_weighted\"]\n",
    "#    \n",
    "#    # Compute coefficient of variation (CV) in percentages.\n",
    "#    cv_acc = (std_acc / mean_acc) * 100\n",
    "#    cv_f1  = (std_f1 / mean_f1) * 100\n",
    "#    \n",
    "#    # Lambda controls the weight given to robustness.\n",
    "#    lambda_val = 0.01\n",
    "#    \n",
    "#    # Composite score: we want high mean and low CV.\n",
    "#    composite = 0.5 * (mean_acc + mean_f1) - lambda_val * 0.5 * (cv_acc + cv_f1)\n",
    "#\n",
    "#    best_index = composite.idxmax()\n",
    "#    return best_index\n",
    "\n",
    "def run_cv(X, y, models, n_splits=5, mode=\"default\", class_weights=None, tune_inner=False, param_grids=None):\n",
    "    \"\"\"\n",
    "    Unified cross-validation runner with optional inner-loop hyperparameter tuning.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.array or pd.DataFrame): Feature matrix.\n",
    "        y (np.array): Labels.\n",
    "        models (dict): Dictionary mapping model names to a tuple: (classifier instance, fit_params dict).\n",
    "                       (If no additional fit parameters are needed, use an empty dict.)\n",
    "        n_splits (int): Number of outer CV folds.\n",
    "        mode (str): One of:\n",
    "            - \"default\": standard CV.\n",
    "            - \"smote\": apply SMOTE oversampling on the training data.\n",
    "            - \"weighted\": for multi-class cost-sensitive learning.\n",
    "            - \"weighted_binary\": for binary cost-sensitive learning (with special handling for XGBoost).\n",
    "        class_weights (dict): Custom class weighting dictionary (e.g., {0: 1.0, 1: 2.0}).\n",
    "        tune_inner (bool): If True and param_grids is provided, perform inner-loop GridSearchCV tuning.\n",
    "        param_grids (dict): Dictionary mapping model names to their hyperparameter grids for tuning.\n",
    "                           Only used if tune_inner is True.\n",
    "        \n",
    "    Returns:\n",
    "        dict: For each model, a dictionary with keys:\n",
    "            \"accuracy\": list of accuracies per outer fold,\n",
    "            \"f1_score\": list of weighted F1 scores per outer fold,\n",
    "            \"log_loss\": list of log losses per outer fold,\n",
    "            \"y_true\": list of true label arrays per fold,\n",
    "            \"y_pred\": list of predicted label arrays per fold,\n",
    "            \"y_pred_proba\": list of predicted probability arrays per fold.\n",
    "    \"\"\"\n",
    "    # Suppress warnings regarding use_label_encoder and feature names\n",
    "    # Ensure X is a DataFrame with valid feature names.\n",
    "    if not hasattr(X, \"columns\"):\n",
    "        X = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Store results as an array of \"folds\" for each model.\n",
    "    results = { name: [] for name in models.keys() }\n",
    "\n",
    "    # Initialize SMOTE if selected.\n",
    "    if mode == \"smote\":\n",
    "        oversampler = SMOTE(random_state=42)\n",
    "\n",
    "    # --- K-fold Outer-loop: Cross-validation ---\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Optionally apply SMOTE.\n",
    "        if mode == \"smote\":\n",
    "            X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # For each model:\n",
    "        for name, (model, fit_params) in models.items():\n",
    "            clf = clone(model)\n",
    "            fold_fit_params = fit_params.copy() if fit_params is not None else {}\n",
    "\n",
    "            # For weighted modes, set class_weight if supported.\n",
    "            if mode in (\"weighted\", \"weighted_binary\") and class_weights is not None:\n",
    "                if 'class_weight' in clf.get_params():\n",
    "                    clf.set_params(class_weight=class_weights)\n",
    "\n",
    "            # Special handling for XGBoost in weighted_binary mode.\n",
    "            if mode == \"weighted_binary\":\n",
    "                try:\n",
    "                    if name == \"XGBoost\" and isinstance(clf, XGBClassifier) and len(np.unique(y_train)) == 2:\n",
    "                        ratio = class_weights.get(1, 1.0) / class_weights.get(0, 1.0)\n",
    "                        clf.set_params(objective='binary:logistic', scale_pos_weight=ratio)\n",
    "                except Exception as e:\n",
    "                    raise ValueError(f\"Error setting scale_pos_weight for XGBoost: {e}\")\n",
    "\n",
    "            # For LightGBM: set eval_set and eval_metric if not already set and verbose to -1.\n",
    "            # This is to avoid printing too much information during training.\n",
    "            if name == \"LightGBM\":\n",
    "                if \"eval_set\" not in fold_fit_params:\n",
    "                    fold_fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "                if \"eval_metric\" not in fold_fit_params:\n",
    "                    fold_fit_params[\"eval_metric\"] = \"logloss\"\n",
    "                clf.set_params(verbose=-1)\n",
    "\n",
    "            # --- K-fold Inner-loop: Hyperparameter tuning ---\n",
    "            hyperparameter_tuning_best_params = None\n",
    "            if tune_inner and param_grids is not None and name in param_grids:\n",
    "                # Perform hyperparameter tuning using GridSearchCV.\n",
    "                print(f\"Tuning hyperparameters for {name}...\")\n",
    "                (best_estimator, best_params) = tune_models(clf, param_grids, X_train, y_train, name, fit_params=fold_fit_params)\n",
    "                clf = best_estimator\n",
    "                hyperparameter_tuning_best_params = best_params\n",
    "            else:\n",
    "                print(f\"Not tuning hyperparameters for {name}.\")\n",
    "                clf.fit(X_train, y_train, **fold_fit_params)\n",
    "\n",
    "            # Evaluate on the outer test set.\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "            # Store each model's results in the \"results\" array, where each outer fold is indexed by k_idx.\n",
    "            # And each element in the results array is a metrics dictionary.\n",
    "            model_metrics = {}\n",
    "            \n",
    "            model_metrics[\"params\"] = hyperparameter_tuning_best_params if hyperparameter_tuning_best_params else \"default\",\n",
    "            model_metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "            model_metrics[\"f1_score\"] = f1_score(y_test, y_pred, average='weighted')\n",
    "            model_metrics[\"log_loss\"] = log_loss(y_test, y_pred_proba)\n",
    "            model_metrics[\"y_true\"] = y_test\n",
    "            model_metrics[\"y_pred\"] = y_pred\n",
    "            model_metrics[\"y_pred_proba\"] = y_pred_proba\n",
    "\n",
    "            print(f\"Model results for {name}:\")\n",
    "            print(f\"Parameters: {model_metrics['params']}\")\n",
    "            print(f\"Accuracy: {model_metrics['accuracy']:.4f}\")\n",
    "            print(f\"F1 Score: {model_metrics['f1_score']:.4f}\")\n",
    "            print(f\"Log Loss: {model_metrics['log_loss']:.4f}\")\n",
    "            \n",
    "            results[name].append(model_metrics)\n",
    "\n",
    "    # Check robustness for each model (using your check_robustness function)\n",
    "    for name in results.keys():\n",
    "        # The metrics stored for each model are in an array of dictionaries, where each dictionary corresponds to a fold.\n",
    "        # We need to extract the metrics from each fold and check their robustness.\n",
    "        acc_values = [results[name][k][\"accuracy\"] for k in range(n_splits)]\n",
    "        f1_values = [results[name][k][\"f1_score\"] for k in range(n_splits)]\n",
    "        ll_values = [results[name][k][\"log_loss\"] for k in range(n_splits)]\n",
    "\n",
    "        print(f\"\\nRobustness for model: {name}\")\n",
    "        acc_robust = check_robustness(\"accuracy\", acc_values)\n",
    "        f1_robust = check_robustness(\"f1_score\", f1_values)\n",
    "        ll_robust = check_robustness(\"log_loss\", ll_values)\n",
    "        if acc_robust and f1_robust and ll_robust:\n",
    "            print(f\"{name} is robust across folds.\\n\")\n",
    "        else:\n",
    "            print(f\"[ERROR] {name} is not robust across folds.\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_cv(results, target_names):\n",
    "    \"\"\"\n",
    "    Aggregates per-fold metrics from a results dictionary and prints overall metrics,\n",
    "    confusion matrix, and classification report using tabulate.\n",
    "    \n",
    "    Parameters:\n",
    "        results (dict): Dictionary mapping model names to a list of per-fold metric dictionaries.\n",
    "                        Each per-fold dictionary must include:\n",
    "                            \"accuracy\": float,\n",
    "                            \"f1_score\": float,\n",
    "                            \"log_loss\": float,\n",
    "                            \"y_true\": true labels for the fold,\n",
    "                            \"y_pred\": predicted labels for the fold,\n",
    "                            \"y_pred_proba\": predicted probability array for the fold,\n",
    "                            \"params\": the model parameters used.\n",
    "        target_names (list): List of class names (e.g., ['HC', 'PD', 'DD']).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of model names to overall metrics including:\n",
    "            \"accuracy_mean\", \"accuracy_std\", \"f1_mean\", \"f1_std\", \n",
    "            \"log_loss_mean\", \"log_loss_std\", \"confusion_matrix\", and \"classification_report\".\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    overall_metrics = {}\n",
    "    table_data = []\n",
    "\n",
    "    # From target_names, print what we are evaluating\n",
    "    print(f\"Evaluating models with target names: {target_names}\")\n",
    "    print(f\"Number of classes: {len(target_names)}\")\n",
    "    print(f\"Classes: {target_names}\")\n",
    "    print(f\"Number of models: {len(results)}\")\n",
    "    print(f\"Models: {list(results.keys())}\")\n",
    "\n",
    "    for name, fold_results in results.items():\n",
    "        # Aggregate per-fold predictions.\n",
    "        y_true_all = np.concatenate([fold[\"y_true\"] for fold in fold_results])\n",
    "        y_pred_all = np.concatenate([fold[\"y_pred\"] for fold in fold_results])\n",
    "        y_pred_proba_all = np.concatenate([fold[\"y_pred_proba\"] for fold in fold_results])\n",
    "        \n",
    "        # Aggregate per-fold metric values.\n",
    "        acc_values = np.array([fold[\"accuracy\"] for fold in fold_results])\n",
    "        f1_values  = np.array([fold[\"f1_score\"] for fold in fold_results])\n",
    "        ll_values  = np.array([fold[\"log_loss\"] for fold in fold_results])\n",
    "        \n",
    "        # Retrieve parameters (assumed constant across folds).\n",
    "        params_val = fold_results[0].get(\"params\", \"default\")\n",
    "        if isinstance(params_val, tuple) and len(params_val) == 1:\n",
    "            params_val = params_val[0]\n",
    "        \n",
    "        # Compute mean and standard deviation for numeric metrics.\n",
    "        acc_mean, acc_std = np.mean(acc_values), np.std(acc_values)\n",
    "        f1_mean,  f1_std  = np.mean(f1_values),  np.std(f1_values)\n",
    "        ll_mean,  ll_std  = np.mean(ll_values),  np.std(ll_values)\n",
    "        \n",
    "        # Compute the overall confusion matrix and classification report.\n",
    "        cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "        clf_report = classification_report(y_true_all, y_pred_all, target_names=target_names, zero_division=0)\n",
    "        \n",
    "        overall_metrics[name] = {\n",
    "            \"params\": params_val,\n",
    "            \"accuracy_mean\": acc_mean,\n",
    "            \"accuracy_std\": acc_std,\n",
    "            \"f1_mean\": f1_mean,\n",
    "            \"f1_std\": f1_std,\n",
    "            \"log_loss_mean\": ll_mean,\n",
    "            \"log_loss_std\": ll_std,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": clf_report,\n",
    "        }\n",
    "        table_data.append([\n",
    "            name,\n",
    "            params_val,\n",
    "            f\"{acc_mean:.4f} Â± {acc_std:.4f}\",\n",
    "            f\"{f1_mean:.4f} Â± {f1_std:.4f}\",\n",
    "            f\"{ll_mean:.4f} Â± {ll_std:.4f}\"\n",
    "        ])\n",
    "        \n",
    "        # Print detailed report for this model.\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"Parameters: {params_val}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(clf_report)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Overall Metrics:\")\n",
    "    print(tabulate(table_data, headers=[\"Model\", \"Params\", \"Accuracy\", \"Weighted F1\", \"Log Loss\"], tablefmt=\"pipe\"))\n",
    "    \n",
    "    return overall_metrics\n",
    "\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        # default: { \"n_estimators\": 100, \"max_depth\": None, \"max_features\": \"sqrt\" }\n",
    "        \"n_estimators\": [100, 300],#, 500],\n",
    "        \"max_depth\": [None, 10],#, 20],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        # default: { \"learning_rate\": 0.3, \"max_depth\": 6, \"subsample\": 1.0 }\n",
    "        \"learning_rate\": [0.1, 0.3],#, 0.01, 0.05],\n",
    "        \"max_depth\": [3, 6],#, 9, 12],\n",
    "        \"subsample\": [0.7, 1.0],#, 0.5, 1.0]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        # default: { \"depth\": 6, \"l2_leaf_reg\": 3 }\n",
    "        \"depth\": [4, 6],#, 10],\n",
    "        \"l2_leaf_reg\": [3, 5],#, 10]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        # default: { \"num_leaves\": 31, \"learning_rate\": 0.1, \"min_child_samples\": 20 }\n",
    "        \"num_leaves\": [20, 31],#, 50, 100],\n",
    "        \"learning_rate\": [0.05, 0.1],#, 0.01, 0.2],\n",
    "        \"min_child_samples\": [10, 20],#, 30, 50]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "     \"RandomForest\": [RandomForestClassifier(random_state=42), {}],\n",
    "     \"XGBoost\": [XGBClassifier(eval_metric='mlogloss', random_state=42), {}],\n",
    "     \"CatBoost\": [CatBoostClassifier(verbose=0, random_state=42), {}],\n",
    "     \"LightGBM\": [LGBMClassifier(random_state=42), {'callbacks': [lgb.early_stopping(10, verbose=0), lgb.log_evaluation(period=0)]}],\n",
    "#     \"LightGBM\": [LGBMClassifier(random_state=42), {}]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos multiclase (PD vs DD vs HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models for TSFEL-temporal pipeline...\n",
      "(469, 1878) (469,)\n",
      "[0 2 0 1 1 1 2 1 1 1]\n",
      "3\n",
      "Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\n",
      "Tuning hyperparameters for RandomForest...\n",
      "Model results for RandomForest:\n",
      "Parameters: ({'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 300},)\n",
      "Accuracy: 0.6596\n",
      "F1 Score: 0.5975\n",
      "Log Loss: 0.7780\n",
      "Tuning hyperparameters for XGBoost...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np.unique(y)) == \u001b[32m3\u001b[39m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPerforming multi-class classification (PD vs DD vs HC) [Default Mode]...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     results_default = \u001b[43mrun_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune_inner\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     overall_default = evaluate_cv(results_default, target_names=[\u001b[33m'\u001b[39m\u001b[33mHC\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDD\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mrun_cv\u001b[39m\u001b[34m(X, y, models, n_splits, mode, class_weights, tune_inner, param_grids)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tune_inner \u001b[38;5;129;01mand\u001b[39;00m param_grids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m param_grids:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Perform hyperparameter tuning using GridSearchCV.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTuning hyperparameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     (best_estimator, best_params) = \u001b[43mtune_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_fit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     clf = best_estimator\n\u001b[32m    169\u001b[39m     hyperparameter_tuning_best_params = best_params\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mtune_models\u001b[39m\u001b[34m(clf, param_grids, X_inner, y_inner, model_name, fit_params)\u001b[39m\n\u001b[32m     24\u001b[39m scoring = {\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mf1_weighted\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mf1_weighted\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     25\u001b[39m grid = GridSearchCV(\n\u001b[32m     26\u001b[39m     estimator=clf,\n\u001b[32m     27\u001b[39m     param_grid=param_grids[model_name],\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m#refit=refit_strategy  # custom refit to pick robust candidate\u001b[39;00m\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (grid.best_estimator_, grid.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1062\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1060\u001b[39m refit_start_time = time.time()\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28mself\u001b[39m.best_estimator_.fit(X, **routed_params.estimator.fit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/santi/uoc/TFG/pads-tfg/.venv/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102d30360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1068c0360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103130360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10707c360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1102d4360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104fd4360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1052f8360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1090fc360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110f18360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106484360>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "for x in X_vals:\n",
    "    X = X_vals[x]\n",
    "    y = y_vals[x]\n",
    "    print(f\"Running models for {x} pipeline...\")\n",
    "    print(X.shape, y.shape)\n",
    "    print(y[:10])\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification (no changes): PD vs DD vs HC\n",
    "    # -----------------------------------------------------------------------------\n",
    "    print(len(np.unique(y)))\n",
    "    if len(np.unique(y)) == 3:\n",
    "        print(\"Performing multi-class classification (PD vs DD vs HC) [Default Mode]...\")\n",
    "        results_default = run_cv(X, y, models, n_splits=5, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "        overall_default = evaluate_cv(results_default, target_names=['HC', 'PD', 'DD'])\n",
    "    else:\n",
    "        print(\"Multi-class classification (PD vs DD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification with SMOTE: PD vs DD vs HC\n",
    "    # -----------------------------------------------------------------------------\n",
    "    if len(np.unique(y)) == 3:\n",
    "        print(\"Performing multi-class classification (PD vs DD vs HC) with SMOTE...\")\n",
    "        results_smote = run_cv(X, y, models, n_splits=5, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "        overall_smote = evaluate_cv(results_smote, target_names=['HC', 'PD', 'DD'])\n",
    "    else:\n",
    "        print(\"Multi-class classification with SMOTE is not possible with the current labels.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Multi-Class Classification with Cost-Sensitive Learning (PD vs DD vs HC)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    if len(np.unique(y)) == 3:\n",
    "        print(\"Performing multi-class classification (PD vs DD vs HC) with cost-sensitive learning...\")\n",
    "        classes = np.unique(y)\n",
    "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "        class_weights_multi = dict(zip(classes, weights))\n",
    "        print(\"Computed class weights:\", class_weights_multi)\n",
    "        \n",
    "        results_weighted = run_cv(\n",
    "            X, y,\n",
    "            models,\n",
    "            n_splits=5,\n",
    "            mode=\"weighted\",\n",
    "            class_weights=class_weights_multi,\n",
    "            tune_inner=True,\n",
    "            param_grids=param_grids\n",
    "        )\n",
    "        overall_weighted = evaluate_cv(results_weighted, target_names=['HC', 'PD', 'DD'])\n",
    "    else:\n",
    "        print(\"Multi-class classification with cost-sensitive learning is not possible with the current labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Binarios (PD vs DD) / (PD vs HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Labels mapping for reference:\n",
    "# 0: HC\n",
    "# 1: PD\n",
    "# 2: DD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD (Default Mode)\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD [Default Mode]...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0, DD (2) becomes 1\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "    \n",
    "    results_pd_dd_default = run_cv(X_pd_dd, y_pd_dd_binary, models, n_splits=5, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_dd_default = evaluate_cv(results_pd_dd_default, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"\\nBinary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC (Default Mode)\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC [Default Mode]...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    results_pd_hc_default = run_cv(X_pd_hc, y_pd_hc, models, n_splits=5, mode=\"default\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_hc_default = evaluate_cv(results_pd_hc_default, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"\\nBinary classification (PD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD with SMOTE\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD with SMOTE...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0, DD (2) becomes 1\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "    \n",
    "    results_pd_dd_smote = run_cv(X_pd_dd, y_pd_dd_binary, models, n_splits=5, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_dd_smote = evaluate_cv(results_pd_dd_smote, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC with SMOTE\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC with SMOTE...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    results_pd_hc_smote = run_cv(X_pd_hc, y_pd_hc, models, n_splits=5, mode=\"smote\", tune_inner=True, param_grids=param_grids)\n",
    "    overall_pd_hc_smote = evaluate_cv(results_pd_hc_smote, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs HC) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs DD with Cost-Sensitive Learning (Weighted Binary Mode)\n",
    "# -------------------------------\n",
    "if set([1, 2]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs DD with cost-sensitive learning...\")\n",
    "    mask_pd_dd = np.isin(y, [1, 2])\n",
    "    X_pd_dd = X[mask_pd_dd]\n",
    "    y_pd_dd = y[mask_pd_dd]\n",
    "    \n",
    "    # Adjust labels: PD (1) becomes 0 and DD (2) becomes 1.\n",
    "    y_pd_dd_binary = y_pd_dd - 1\n",
    "\n",
    "    # Compute balanced class weights from the original y_pd_dd\n",
    "    classes = np.unique(y_pd_dd)  # Typically [1, 2]\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_pd_dd)\n",
    "    # Create a dictionary mapping original classes to their weight.\n",
    "    class_weights_pd_dd = dict(zip(classes, weights))\n",
    "    # Remap keys to reflect the new labels: PD becomes 0, DD becomes 1.\n",
    "    class_weights_pd_dd = {k - 1: v for k, v in class_weights_pd_dd.items()}\n",
    "    print(\"Computed class weights for PD vs DD:\", class_weights_pd_dd)\n",
    "    \n",
    "    results_pd_dd_weighted = run_cv(\n",
    "        X_pd_dd,\n",
    "        y_pd_dd_binary,\n",
    "        models,\n",
    "        n_splits=5,\n",
    "        mode=\"weighted_binary\",\n",
    "        class_weights=class_weights_pd_dd,\n",
    "        tune_inner=True,\n",
    "        param_grids=param_grids\n",
    "    )\n",
    "    overall_pd_dd_weighted = evaluate_cv(results_pd_dd_weighted, target_names=['PD', 'DD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs DD) is not possible with the current labels.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Binary Classification: PD vs HC with Cost-Sensitive Learning (Weighted Binary Mode)\n",
    "# -------------------------------\n",
    "if set([1, 0]).issubset(set(y)):\n",
    "    print(\"\\nPerforming binary classification: PD vs HC with cost-sensitive learning...\")\n",
    "    mask_pd_hc = np.isin(y, [1, 0])\n",
    "    X_pd_hc = X[mask_pd_hc]\n",
    "    y_pd_hc = y[mask_pd_hc]\n",
    "    \n",
    "    # Compute balanced class weights from the current training subset.\n",
    "    # Here, we assume that in PD vs HC, class 0 = HC and class 1 = PD.\n",
    "    classes = np.unique(y_pd_hc)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_pd_hc)\n",
    "    class_weights_pd_hc = dict(zip(classes, weights))\n",
    "    print(\"Computed class weights:\", class_weights_pd_hc)\n",
    "    \n",
    "    results_pd_hc_weighted = run_cv(\n",
    "        X_pd_hc,\n",
    "        y_pd_hc,\n",
    "        models,\n",
    "        n_splits=5,\n",
    "        mode=\"weighted_binary\",\n",
    "        class_weights=class_weights_pd_hc,\n",
    "        tune_inner=True,\n",
    "        param_grids=param_grids\n",
    "    )\n",
    "    overall_pd_hc_weighted = evaluate_cv(results_pd_hc_weighted, target_names=['HC', 'PD'])\n",
    "else:\n",
    "    print(\"Binary classification (PD vs HC) is not possible with the current labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
